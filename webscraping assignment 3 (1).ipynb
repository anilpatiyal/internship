{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0796f04",
   "metadata": {},
   "source": [
    "Write a python program which searches all the product under a particular product from www.amazon.in. The \n",
    "product to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search for \n",
    "guitars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010439bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6bcb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://www.amazon.in./\")\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "try:\n",
    "    search_element=driver.find_element(By.XPATH,'//div[@class=\"nav-search-field \"]/input')\n",
    "    search_element.send_keys(input(\"Enter Guitar\"))\n",
    "except ElementNotInteractableException as e:\n",
    "    print(\"Exception Raised:\",e)   \n",
    "    \n",
    "    \n",
    "    \n",
    "try:\n",
    "    search_click=driver.find_element(By.XPATH,'//div[@class=\"nav-search-submit nav-sprite\"]/span')\n",
    "    search_click.click()\n",
    "except ElementNotInteractableException as e:\n",
    "    print(\"Exception Raised: \",e)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c69b6de",
   "metadata": {},
   "source": [
    "In the above question, now scrape the following details of each product listed in first 3 pages of your search \n",
    "results and save it in a data frame and csv. In case if any product has less than 3 pages in search results then \n",
    "scrape all the products available under that product name. Details to be scraped are: \"Brand \n",
    "Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and \n",
    "“Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a1485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "guitar_url=[]\n",
    "\n",
    "start=0\n",
    "end=3\n",
    "\n",
    "for page in range(start,end):\n",
    "    try:\n",
    "        url=driver.find_elements(By.XPATH,'//h2[@class=\"a-size-mini a-spacing-none a-color-base s-line-clamp-4\"]/a')\n",
    "        for i in url:\n",
    "            guitar_url.append(i.get_attribute('href'))\n",
    "    except WebDriverException as e:\n",
    "        print(\"WebDriverException\",e)\n",
    "        \n",
    "   \n",
    "        \n",
    "try:\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"s-pagination-item s-pagination-next s-pagination-button s-pagination-separator\"]')\n",
    "    next_button.click()\n",
    "except WebDriverException as e:\n",
    "    print(\"WebDriverException\",e)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6704214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(guitar_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425a3178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import TimeoutException,NoSuchElementException, ElementNotInteractableException,WebDriverException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbedf9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_name=[]\n",
    "product_name=[]\n",
    "price=[]\n",
    "exchange=[]\n",
    "expected_delivery=[]\n",
    "availability=[]\n",
    "\n",
    "for i in guitar_url:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        brand=driver.find_element(By.XPATH,'//td[@class=\"a-span9\"]')\n",
    "        brand_name.append(brand.text)\n",
    "    except NoSuchElementException :\n",
    "        brand_name.append(\"-\")\n",
    "    try:\n",
    "        product=driver.find_element(By.XPATH,'//div[@class=\"a-section a-spacing-none\"]/h1/span')\n",
    "        product_name.append(product.text)\n",
    "    except NoSuchElementException:\n",
    "        product_name.append(\"-\")\n",
    "    try:\n",
    "        cost=driver.find_element(By.XPATH,'//span[@class=\"a-price aok-align-center reinventPricePriceToPayMargin priceToPay\"]')\n",
    "        price.append(cost.text)\n",
    "    except NoSuchElementException:\n",
    "        price.append(\"-\")\n",
    "    try:\n",
    "        exchanges=driver.find_element(By.XPATH,'/html/body/div[2]/div/div[5]/div[3]/div[4]/div[24]/div[2]/div/div/div/div[2]/div/ol/li[3]/div/span/div[2]/span')\n",
    "        exchange.append(exchanges.text)\n",
    "    except NoSuchElementException:\n",
    "        exchange.append(\"-\")\n",
    "    try:\n",
    "        expected=driver.find_element(By.XPATH,'//div[@class=\"a-section a-spacing-none\"]/div/div/span[1]')\n",
    "        expected_delivery.append(expected.text)\n",
    "    except NoSuchElementException:\n",
    "        expected_delivery.append(\"-\")\n",
    "    try:\n",
    "        available=driver.find_element(By.XPATH,'//div[@class=\"a-section\"]/div/span')\n",
    "        availability.append(available.text)\n",
    "    except NoSuchElementException:\n",
    "        availability.append(\"-\")\n",
    "        \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a0c5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(brand_name),len(product_name),len(price),len(exchange),len(expected_delivery),len(availability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a654b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_guitar=pd.DataFrame({\"Brand\":brand_name,\"Title\":product_name,\"Cost\":price,\"Expected_delivery\":expected_delivery,\"Available\":availability})\n",
    "df_guitar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f7ba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_guitar.to_csv(\"guitar.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84f9234",
   "metadata": {},
   "source": [
    "Write a python program to scrape a data for all available Hostels from https://www.hostelworld.com/ in\n",
    "“London” location. You have to scrape hostel name, distance from city centre, ratings, total reviews, overall\n",
    "reviews, privates from price, dorms from price, facilities and property description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260365aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import WebDriverException, NoSuchElementException,ElementNotInteractableException\n",
    "from selenium.common.exceptions import TimeoutException, JavascriptException \n",
    "import time\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17807128",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://www.hostelworld.com/\")\n",
    "time.sleep(2)\n",
    "\n",
    "list_menu=driver.find_element(By.XPATH,'//div[@class=\"menu-wrapper\"][2]')\n",
    "list_menu.click()\n",
    "\n",
    "try:\n",
    "    search_tag=driver.find_element(By.XPATH,'/html/body/div[3]/div/div/div[2]/div[2]/header/div[2]/div[2]/div/div/div/div[2]/div/ul/li[1]/button/span/div')\n",
    "    search_tag.click()\n",
    "except NoSuchElementException as e:\n",
    "    print(\"NoSuchElementException\",e)\n",
    "\n",
    "time.sleep(2)\n",
    "    \n",
    "try:\n",
    "    hostel_tag=WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,'//div[@class=\"item-text\"]')))\n",
    "    hostel_tag.click()\n",
    "except ElementNotInteractableException  as e:\n",
    "    print(\"ElementNotInteractableException \",e)\n",
    "    \n",
    "time.sleep(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1190083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'search')))\n",
    "    location_input = driver.find_element(By.XPATH, '//div[@class=\"search\"]/label/input')\n",
    "    location_input.send_keys(input(\"Enter location\"))\n",
    "except TimeoutException:\n",
    "    print(\"Location input element not found within timeout period\")\n",
    "\n",
    "try:\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//div[@class=\"label\"]/span')))\n",
    "    location_friz = driver.find_element(By.XPATH, '//div[@class=\"label\"]/span')\n",
    "    location_friz.click()\n",
    "except NoSuchElementException as e:\n",
    "    print(\"NoSuchElementException\", e)\n",
    "\n",
    "try:\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//button[@class=\"search-button\"]')))\n",
    "    search_click = driver.find_element(By.XPATH, '//button[@class=\"search-button\"]')\n",
    "    search_click.click()\n",
    "except NoSuchElementException as e:\n",
    "    print(\"NoSuchElementException \", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41382284",
   "metadata": {},
   "outputs": [],
   "source": [
    "hostel_name=[]\n",
    "distance_city=[]\n",
    "ratings=[]\n",
    "total_review=[]\n",
    "private_price=[]\n",
    "dorm_price=[]\n",
    "\n",
    "property_description=[]\n",
    "\n",
    "\n",
    "try:\n",
    "    hostel_name_tag=driver.find_elements(By.XPATH,'//div[@class=\"property-name\"]/span')\n",
    "    for i in hostel_name_tag:\n",
    "        hostel_name.append(i.text)\n",
    "except JavascriptException as e:\n",
    "    print(\"JavascriptException\",e)\n",
    "    \n",
    "\n",
    "\n",
    "try:\n",
    "    distance_tag=driver.find_elements(By.XPATH,'//div[@class=\"property-distance\"]/span[2]')\n",
    "    for i in distance_tag:\n",
    "        distance_city.append(i.text)\n",
    "except JavascriptException as e:\n",
    "    print(\"JavascriptException\",e)\n",
    "    \n",
    "try:\n",
    "    rating_tag=driver.find_elements(By.XPATH,'//div[@class=\"property-info-header\"]/div/div/div[1]')\n",
    "    for i in rating_tag:\n",
    "        ratings.append(i.text)\n",
    "except JavascriptException as e:\n",
    "    print(\"JavascriptException\",e)\n",
    "    \n",
    "try:\n",
    "    tot_review_tag=driver.find_elements(By.XPATH,'//div[@class=\"property-info-header\"]/div/div/div[2]')\n",
    "    for i in tot_review_tag:\n",
    "        total_review.append(i.text)\n",
    "except JavascriptException as e:\n",
    "    print(\"JavascriptException\",e)\n",
    "\n",
    "    \n",
    "try:\n",
    "    price_tag=driver.find_elements(By.XPATH,'//div[@class=\"property-accommodation-prices\"]/div[1]')\n",
    "    for i in price_tag:\n",
    "        private_price.append(i.text)\n",
    "except NoSuchElementExceptions as e:\n",
    "    private_price.append(\"-\")\n",
    "    print(\"NoSuchElementExceptions\",e)\n",
    "    \n",
    "try:\n",
    "    dorm_price_tag=driver.find_elements(By.XPATH,'//div[@class=\"property-accommodation-prices\"]/div[2]')\n",
    "    for i in dorm_price_tag:\n",
    "        dorm_price.append(i.text)\n",
    "except NoSuchElementExceptions as e:\n",
    "    dorm_price.append(\"-\")\n",
    "    print(\"NoSuchElementExceptions\",e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1fa841",
   "metadata": {},
   "outputs": [],
   "source": [
    "hostel_url = []\n",
    "\n",
    "try:\n",
    "    url_elements = driver.find_elements(By.XPATH, '//div[@class=\"property-card\"]/a')\n",
    "    for element in url_elements:\n",
    "        hostel_url.append(element.get_attribute('href'))\n",
    "except WebDriverExceptions as e:\n",
    "    print(\"Exceptions\", e)\n",
    "    \n",
    "time.sleep(2)\n",
    "    \n",
    "for url in hostel_url:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    try:\n",
    "        property_tag = driver.find_element(By.XPATH,'//div[@class=\"content collapse-content\"]')\n",
    "        property_description.append(property_tag.text)\n",
    "    except NoSuchElementException as e:\n",
    "        property_description.append(\"-\")\n",
    "        print(\"NoSuchElementException\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f15c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(hostel_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36f78c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_hostel=pd.DataFrame({\"Title\":hostel_name,\"Distance\":distance_city,\"Rating\":ratings,\"Total_review\":total_review,\"Private_price\":private_price,\"Dorm_price\":dorm_price})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07825bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hostel_name=[]\n",
    "distance_city=[]\n",
    "ratings=[]\n",
    "total_review=[]\n",
    "private_price=[]\n",
    "dorm_price=[]\n",
    "\n",
    "property_description=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a519d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(hostel_name),len(distance_city),len(ratings),len(total_review),len(private_price),len(dorm_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e0bc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(property_description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0c00bb",
   "metadata": {},
   "source": [
    "Write a program to extract at least 500 Comments, Comment upvote and time when comment was posted\n",
    "from any YouTube Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d2f135",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import WebDriverException, NoSuchElementException\n",
    "import requests\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43cb50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://www.youtube.com/watch?v=eLS5GlhjpcA\")\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.youtube.com/watch?v=eLS5GlhjpcA\")\n",
    "time.sleep(2)\n",
    "\n",
    "# Lists to store comments, upvotes, and times\n",
    "comments = []\n",
    "upvotes = []\n",
    "timestamps = []\n",
    "\n",
    "# Scroll until at least 500 comments are loaded\n",
    "while len(comments) <= 500 or len(upvotes) <= 500 or len(timestamps) <= 500:\n",
    "    driver.execute_script(\"window.scrollBy(0,500)\")\n",
    "    time.sleep(2)  # Give time for comments to load\n",
    "\n",
    "    try:\n",
    "        comment_tags = driver.find_elements(By.XPATH, '//yt-formatted-string[@id=\"content-text\"]')\n",
    "        for element in comment_tags:\n",
    "            comments.append(element.text)\n",
    "    except NoSuchElementException as e:\n",
    "        comments.append(\"-\")\n",
    "        print(\"NoSuchElementException\", e)\n",
    "\n",
    "    try:\n",
    "        upvote_tags = driver.find_elements(By.XPATH, '//span[@id=\"vote-count-middle\"]')\n",
    "        for vote in upvote_tags:\n",
    "            upvotes.append(vote.text)\n",
    "    except NoSuchElementException as e:\n",
    "        upvotes.append(\"-\")\n",
    "        print(\"NoSuchElementException\", e)\n",
    "\n",
    "    try:\n",
    "        time_tags = driver.find_elements(By.XPATH, '//a[@class=\"yt-simple-endpoint style-scope yt-formatted-string\"]')\n",
    "        for times in time_tags:\n",
    "            timestamps.append(times.text)\n",
    "    except NoSuchElementException as e:\n",
    "        timestamps.append(\"-\")\n",
    "        print(\"NoSuchElementException\", e)\n",
    "\n",
    "print(\"Number of comments:\", len(comments))\n",
    "print(\"Number of upvotes:\", len(upvotes))\n",
    "print(\"Number of timestamps:\", len(timestamps))\n",
    "\n",
    "# Close the driver\n",
    "driver.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bd4493",
   "metadata": {},
   "source": [
    "#3. Write a python program to access the search bar and search button on images.google.com and scrape 10 images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’. 3. Write a python program to access the search bar and search button on images.google.com and scrape 10 images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a642486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException,StaleElementReferenceException, WebDriverException,TimeoutException\n",
    "import time\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3253f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://www.google.co.in/\")\n",
    "time.sleep(5)\n",
    "\n",
    "try:\n",
    "    click_images=driver.find_element(By.XPATH,'//div[@class=\"gb_I gb_J\"][2]')\n",
    "    click_images.click()\n",
    "except NoSuchElementException as e:\n",
    "    print(\"NoSuchElementException\",e)\n",
    "try:\n",
    "    fruit_search=driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/div/div[2]/textarea')\n",
    "    fruit_search.send_keys(input(\"Enter any keyword\"))\n",
    "except ElementNotInteractableException as e:\n",
    "    print(\"ElementNotInteractableException\",e)\n",
    "try:\n",
    "    fruit_click=driver.find_element(By.XPATH,'//span[@class=\"z1asCe MZy1Rb\"]')\n",
    "    fruit_click.click()\n",
    "    time.sleep(3)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"NoSuchElementException\",e)    \n",
    "\n",
    "\n",
    "for _ in range(20):\n",
    "    driver.execute_script(\"window.scrollBy(0,500)\")\n",
    "    \n",
    "img_url = []\n",
    "images=driver.find_elements(By.XPATH,'//img[@class=\"rg_i Q4LuWd\"]')\n",
    "for image in images:\n",
    "    source=image.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if(source[0:4] =='http'):\n",
    "            img_url.append(source)\n",
    "            \n",
    "for i in range(len(img_url)):\n",
    "    if i > 10:\n",
    "        break\n",
    "    print(\"Downloading {0} of {1} images\" .format(i, 10))\n",
    "    response= requests.get(img_url[i])\n",
    "    file = open(r\"C:\\Users\\lenovo\\Desktop\\roboflip\"+str(i)+\".jpg\",\"wb\")\n",
    "    file.write(response.content)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddb0af8",
   "metadata": {},
   "source": [
    "Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com and scrape following details for all the search results displayed on 1st page. Details to be scraped: “Brand Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”, “Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the details is missing then replace it by “- “. Save your results in a dataframe and CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7809a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "time.sleep(5)\n",
    "\n",
    "try:\n",
    "    mob_search=driver.find_element(By.XPATH,'//input[@class=\"Pke_EE\"]')\n",
    "    mob_search.send_keys(input(\"Enter mobile name\"))\n",
    "except ElementNotInteractableException as e:\n",
    "    print(\" ElementNotInteractableException \",e)\n",
    "    \n",
    "mob_click=driver.find_element(By.XPATH,'//button[@class=\"_2iLD__\"]')\n",
    "mob_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3df861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mob_url=[]\n",
    "\n",
    "try:\n",
    "    url=driver.find_elements(By.XPATH,'//div[@class=\"_2kHMtA\"]/a')\n",
    "    for i in url:\n",
    "        mob_url.append(i.get_attribute('href'))\n",
    "except WebDriverException as e:\n",
    "    print(\"WebDriverException\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcd02c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "brand_name=[]\n",
    "mobile_name=[]\n",
    "colour=[]\n",
    "ram=[]\n",
    "rom=[]\n",
    "primary_cam=[]\n",
    "display_size=[]\n",
    "battery_capacity=[]\n",
    "price=[]\n",
    "\n",
    "\n",
    "\n",
    "for i in mob_url:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        company=driver.find_element(By.XPATH,'//span[@class=\"B_NuCI\"]')\n",
    "        brand_name.append(company.text)\n",
    "    except NoSuchElementException:\n",
    "        brand_name.append(\"-\")\n",
    "    try:\n",
    "        more_click=driver.find_element(By.XPATH,'//button[@class=\"_2KpZ6l _1FH0tX\"]')\n",
    "        more_click.click()\n",
    "    except WebDriverException as e:\n",
    "        print(\"WebDriverException\",e)\n",
    "    try:\n",
    "        title=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[8]/div[4]/div/div[2]/div/div[1]/table/tbody/tr[3]/td[2]/ul/li')\n",
    "        mobile_name.append(title.text)\n",
    "    except NoSuchElementException:\n",
    "        mobile_name.append(\"-\")\n",
    "    try:\n",
    "        colours=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[8]/div[4]/div/div[2]/div/div[1]/table/tbody/tr[4]/td[2]/ul/li')\n",
    "        colour.append(colours.text)\n",
    "    except NoSuchElementException:\n",
    "        colour.append(\"-\")\n",
    "    try:\n",
    "        rams=driver.find_element(By.XPATH,'//li[@class=\"_21Ahn-\"][1]')\n",
    "        ram.append(rams.text)\n",
    "    except NoSuchElementException:\n",
    "        ram.append(\"-\")\n",
    "    except NoSuchElementException:\n",
    "        ram.append(\"-\")\n",
    "    try:\n",
    "        roms=driver.find_element(By.XPATH,'//li[@class=\"_21Ahn-\"][1]')\n",
    "        rom.append(roms.text)\n",
    "    except NoSuchElementException:\n",
    "        rom.append(\"-\")\n",
    "    try:\n",
    "        camera=driver.find_element(By.XPATH,'//li[@class=\"_21Ahn-\"][3]')\n",
    "        primary_cam.append(camera.text)\n",
    "    except NoSuchElementException:\n",
    "        primary_cam.append(\"-\")\n",
    "    try:\n",
    "        size=driver.find_element(By.XPATH,'//li[@class=\"_21Ahn-\"][2]')\n",
    "        display_size.append(size.text)\n",
    "    except NoSuchElementException:\n",
    "        display_size.append(\"-\")\n",
    "    try:\n",
    "        battery=driver.find_element(By.XPATH,'//li[@class=\"_21Ahn-\"][4]')\n",
    "        battery_capacity.append(battery.text)\n",
    "    except NoSuchElementException:\n",
    "        battery_capacity.append(\"-\")\n",
    "    try:\n",
    "        cost=driver.find_element(By.XPATH,'//div[@class=\"_30jeq3 _16Jk6d\"]')\n",
    "        price.append(cost.text)\n",
    "    except NoSuchElementException:\n",
    "        price.append(\"-\")\n",
    "    \n",
    "\n",
    "driver.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbe1694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def find_oneplus(name):\n",
    "    branded_name=[]\n",
    "    for brand in name:\n",
    "        brands=re.findall(r\"^OnePlus\",brand)\n",
    "        branded_name.append(brands)\n",
    "    return branded_name\n",
    "        \n",
    "    \n",
    "title=find_oneplus(brand_name)\n",
    "print(title)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee89bb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extracts_mobile_name(smart):\n",
    "    mobile_name=[]\n",
    "    for mob in smart:\n",
    "        mobiles=re.findall(\"\\s(.*)5G\",mob)\n",
    "        mobile_name.append(mobiles)\n",
    "    return mobile_name\n",
    "\n",
    "smartphone=extracts_mobile_name(brand_name)\n",
    "\n",
    "print(smartphone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec87493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracts_color_name(rang):\n",
    "    colour_name=[]\n",
    "    for col in rang:\n",
    "        colours=re.findall(\"\\((.*),\",col)\n",
    "        colour_name.append(colours)\n",
    "    return colour_name\n",
    "\n",
    "texture=extracts_color_name(brand_name)\n",
    "\n",
    "print(texture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b918f117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ram(fast):\n",
    "    ram_put=[]\n",
    "    for r in fast:\n",
    "        rams=re.findall(r\"(\\b\\d+)\\s*GB\\s*RAM\",r)\n",
    "        ram_put.append(rams)\n",
    "    return ram_put\n",
    "\n",
    "random=extract_ram(ram)\n",
    "\n",
    "print(random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db05a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rom(read):\n",
    "    rom_put=[]\n",
    "    for i in read:\n",
    "        roms=re.findall(r\"(\\b\\d+)\\s*GB\\s*ROM\",i)\n",
    "        rom_put.append(roms)\n",
    "    return rom_put\n",
    "\n",
    "memory=extract_rom(rom)\n",
    "\n",
    "print(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60207551",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(title),len(mobile_name),len(colour),len(ram),len(rom),len(primary_cam),len(display_size),len(battery_capacity),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1d90f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as  pd\n",
    "\n",
    "df=pd.DataFrame({\"Brand_name\":title,\"Smartphone_name\":smartphone,\"Colour\":texture,\"RAM\":random,\"ROM\":memory,\"Prinary_camera\":primary_cam,\"Display_size\":display_size,\"Battery_capacity\":battery_capacity,\"Price\":price,\"Product_url\":mob_url})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80812517",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"oneplus.csv\",index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8d3513",
   "metadata": {},
   "source": [
    "Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5c4f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver1=webdriver.Chrome()\n",
    "driver1.get(\"https://www.google.com/maps/@28.5220658,77.25056,15z?entry=ttu\")\n",
    "time.sleep(2)\n",
    "\n",
    "try:\n",
    "    location_input=driver1.find_element(By.XPATH,'//input[@class=\"searchboxinput xiQnY\"]')\n",
    "    location_input.send_keys(input(\"Enter any location :\"))\n",
    "except WebDriverException as e:\n",
    "    print(\"WebDriverException\",e)\n",
    "time.sleep(2)\n",
    "\n",
    "try:\n",
    "    location_search=driver1.find_element(By.XPATH,'//span[@class=\"google-symbols\"]')\n",
    "    location_search.click()\n",
    "except WebDriverException as e:\n",
    "    print(\"WebDriverException\",e)\n",
    "time.sleep(2)\n",
    "\n",
    "try:\n",
    "    url_string=driver1.current_url\n",
    "    print(\"URL Extracted: \",url_string)\n",
    "    lat_long=re.findall(r'@(.*)data',url_string)\n",
    "    if len(lat_long):\n",
    "        lat_long_str=lat_long[0].split(',')\n",
    "        if len(lat_long_str)>=2:\n",
    "            lat=lat_long_str[0]\n",
    "            long=lat_long_str[1]\n",
    "        print(\"Latitude = {}, Longitude = {}\".format(lat,long))\n",
    "        \n",
    "except Exception as e:\n",
    "    print(\"Error: \", str(e))\n",
    "    \n",
    "    \n",
    "driver1.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4612893",
   "metadata": {},
   "source": [
    "Write a program to scrap all the available details of best business laptops from digit.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa0cb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time \n",
    "import requests\n",
    "from selenium.common.exceptions import WebDriverException, ElementNotInteractableException, StaleElementReferenceException, NoSuchElementException, TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfa2a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://www.digit.in/\")\n",
    "time.sleep(3)\n",
    "\n",
    "try:\n",
    "    menu_click=driver.find_element(By.XPATH,'//button[@class=\"dl-trigger\"]')\n",
    "    menu_click.click()\n",
    "except ElementNotInteractableException as e:\n",
    "    print(\"ElementNotInteractableException\",e)\n",
    "time.sleep(3)\n",
    "\n",
    "try:\n",
    "    top_click=driver.find_element(By.XPATH,'/html/body/div[4]/div/ul/li[4]/a')\n",
    "    top_click.click()\n",
    "except ElementNotInteractableException as e:\n",
    "    print(\"ElementNotInteractableException\",e)\n",
    "time.sleep(3)\n",
    "\n",
    "try:\n",
    "    laptop_click=driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/div/div[2]/div[1]/div[3]/div[5]/p/a')\n",
    "    laptop_click.click()\n",
    "except NoSuchElementException as e:\n",
    "    print(\"NoSuchElementException\",e) \n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d13694d",
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop_url=[]\n",
    "\n",
    "try:\n",
    "    url=driver.find_elements(By.XPATH,'//h3[@class=\"font130 mt0 mb10 mobilesblockdisplay \"]/a')\n",
    "    for i in url:\n",
    "        laptop_url.append(i.get_attribute('href'))\n",
    "except WebDriverException as e:\n",
    "    print('WebDriverException',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a905ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "title=[]\n",
    "op_system=[]\n",
    "display_size=[]\n",
    "storage=[]\n",
    "processor=[]\n",
    "\n",
    "for i in laptop_url:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    try:\n",
    "        laptop_title=driver.find_element(By.XPATH,'//h1[@class=\"floatleft tabletblockdisplay pr20 \"]')\n",
    "        title.append(laptop_title.text)\n",
    "    except NoSuchElementException:\n",
    "        title.append(\"-\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "    try:\n",
    "        ops=driver.find_element(By.XPATH,'/html/body/div[2]/div[3]/div[1]/div/div/div/div/div[2]/div[1]/div[4]/div[3]/div/div/ul/li[1]/div/p[2]')\n",
    "        op_system.append(ops.text)\n",
    "    except NoSuchElementException:\n",
    "        op_system.append(\"-\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "    try:\n",
    "        size=driver.find_element(By.XPATH,'/html/body/div[2]/div[3]/div[1]/div/div/div/div/div[2]/div[1]/div[4]/div[3]/div/div/ul/li[4]/div/p[2]')\n",
    "        display_size.append(size.text)\n",
    "    except NoSuchElementException:\n",
    "        display_size.append(\"-\")\n",
    "    time.sleep(3)\n",
    "     \n",
    "    try:\n",
    "        storages=driver.find_element(By.XPATH,'/html/body/div[2]/div[3]/div[1]/div/div/div/div/div[2]/div[1]/div[4]/div[3]/div/div/ul/li[3]/div/p[2]')\n",
    "        storage.append(storages.text)\n",
    "    except NoSuchElementException:\n",
    "        storage.append(\"-\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "    try:\n",
    "        process=driver.find_element(By.XPATH,'/html/body/div[2]/div[3]/div[1]/div/div/div/div/div[2]/div[1]/div[4]/div[3]/div/div/ul/li[2]/div/p[2]')\n",
    "        processor.append(process.text)\n",
    "    except NoSuchElementException:\n",
    "        processor.append(\"-\")\n",
    "    time.sleep(3)\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9b7098",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(title),len(op_system),len(display_size),len(resolution),len(storage),len(laptop_url),len(processor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80179d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_laptop=pd.DataFrame({\"Title\":title,\"Operating_system\":op_system,\"Display\":display_size,\"Processor\":processor,\"Storage\":storage,\"Laptop_url\":laptop_url})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f215c980",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_laptop.to_csv(\"business_laptop.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4af716c",
   "metadata": {},
   "source": [
    "Write a python program to scrape the details for all billionaires from www.forbes.com. Details to be scrapped: “Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”, “Industry”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4b18c194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import InvalidSessionIdException ,NoSuchFrameException,TimeoutException,ElementNotVisibleException\n",
    "import time\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e61996d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://www.forbes.com/?sh=e4946b92254c\")\n",
    "time.sleep(2)\n",
    "\n",
    "list_click=driver.find_element(By.XPATH,'//div[@class=\"_8FT-x3t4\"]')\n",
    "list_click.click()\n",
    "time.sleep(2)\n",
    "\n",
    "try:\n",
    "    billion_in=driver.find_element(By.XPATH,'/html/body/div[1]/header/nav/div[1]/div[1]/div/div[2]/ul/li[2]/div[1]/span')\n",
    "    billion_in.click()\n",
    "except NoSuchElementException as e:\n",
    "    print(\"NoSuchElementException\",e)\n",
    "time.sleep(2)\n",
    "\n",
    "try:\n",
    "    world=driver.find_element(By.XPATH,'//li[@class=\"TjJgrPSg _2bNo56RE secondary\"]')\n",
    "    world.click()\n",
    "except ElementClickInterceptedException as e:\n",
    "    print(\"ElementClickInterceptedException\",e)\n",
    "time.sleep(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "740a7d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=[]\n",
    "name=[]\n",
    "net_worth=[]\n",
    "industry=[]\n",
    "\n",
    "try:\n",
    "    rank_tag=driver.find_elements(By.XPATH,'//div[@role=\"cell\"][1]')\n",
    "    for i in rank_tag:\n",
    "        rank.append(i.text)\n",
    "except InvalidSessionIdException  as e:\n",
    "    print(\"InvalidSessionIdException \",e)\n",
    "try:\n",
    "    name_tag=driver.find_elements(By.XPATH,'//div[@role=\"cell\"][2]')\n",
    "    for i in name_tag:\n",
    "        name.append(i.text)\n",
    "except InvalidSessionIdException  as e:\n",
    "    print(\"InvalidSessionIdException \",e)\n",
    "try:\n",
    "    net_worth_tag=driver.find_elements(By.XPATH,'//div[@role=\"cell\"][3]')\n",
    "    for i in net_worth_tag:\n",
    "        net_worth.append(i.text)\n",
    "except InvalidSessionIdException  as e:\n",
    "    print(\"InvalidSessionIdException \",e)\n",
    "time.sleep(2)\n",
    "\n",
    "try:\n",
    "    industry_tag=driver.find_elements(By.XPATH,'//div[@role=\"cell\"][4]')\n",
    "    for i in industry_tag:\n",
    "        industry.append(i.text)\n",
    "except InvalidSessionIdException  as e:\n",
    "    print(\"InvalidSessionIdException \",e)        \n",
    "\n",
    "    \n",
    "driver.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cd17c452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>name</th>\n",
       "      <th>net_worth</th>\n",
       "      <th>industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Bernard Arnault &amp; family</td>\n",
       "      <td>$233 B</td>\n",
       "      <td>Fashion &amp; Retail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>$195 B</td>\n",
       "      <td>Automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Jeff Bezos</td>\n",
       "      <td>$194 B</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>Mark Zuckerberg</td>\n",
       "      <td>$177 B</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>Larry Ellison</td>\n",
       "      <td>$141 B</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195.</td>\n",
       "      <td>Lei Jun</td>\n",
       "      <td>$10.9 B</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>195.</td>\n",
       "      <td>Georg Schaeffler</td>\n",
       "      <td>$10.9 B</td>\n",
       "      <td>Automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>195.</td>\n",
       "      <td>Marcel Herrmann Telles &amp; family</td>\n",
       "      <td>$10.9 B</td>\n",
       "      <td>Food &amp; Beverage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>199.</td>\n",
       "      <td>David Velez &amp; family</td>\n",
       "      <td>$10.8 B</td>\n",
       "      <td>Finance &amp; Investments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200.</td>\n",
       "      <td>Suleiman Kerimov &amp; family</td>\n",
       "      <td>$10.7 B</td>\n",
       "      <td>Finance &amp; Investments</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rank                             name net_worth               industry\n",
       "0      1.         Bernard Arnault & family    $233 B       Fashion & Retail\n",
       "1      2.                        Elon Musk    $195 B             Automotive\n",
       "2      3.                       Jeff Bezos    $194 B             Technology\n",
       "3      4.                  Mark Zuckerberg    $177 B             Technology\n",
       "4      5.                    Larry Ellison    $141 B             Technology\n",
       "..    ...                              ...       ...                    ...\n",
       "195  195.                          Lei Jun   $10.9 B             Technology\n",
       "196  195.                 Georg Schaeffler   $10.9 B             Automotive\n",
       "197  195.  Marcel Herrmann Telles & family   $10.9 B        Food & Beverage\n",
       "198  199.             David Velez & family   $10.8 B  Finance & Investments\n",
       "199  200.        Suleiman Kerimov & family   $10.7 B  Finance & Investments\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rich=pd.DataFrame({\"rank\":rank,\"name\":name,\"net_worth\":net_worth,\"industry\":industry})\n",
    "\n",
    "df_rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd5c7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
