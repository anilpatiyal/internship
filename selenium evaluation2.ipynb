{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "739c9982",
   "metadata": {},
   "source": [
    "All the questons must be done in a single Jupyternotebook. \n",
    "2. There should be proper comments in code.\n",
    "Q1: In this queston you have to scrape data using the flters available on the webpage You have to use the locaton and \n",
    "salary flter. \n",
    "You have to scrape data for  “Data Scientst” d esignaton for frst 10 job results. \n",
    "You have to scrape the job-ttle, job-locaton, company name, experience required. \n",
    "The locaton flter to be used is  “Delhi/NCR”. T he salary flter to be used is “ 3-6” l akhs \n",
    "The task will be done as shown in the below steps: \n",
    "1. frst get the web page  htps://www.naukri.com/\n",
    "2. Enter “ Data Scientst” i n “ Skill, Designatons, and Companies” f eld. \n",
    "3. Then click the search buton. \n",
    "4. Then apply the locaton flter and salary flter by checking the respectve boxes \n",
    "5. Then scrape the data for the frst 10 jobs results you get. \n",
    "6. Finally create a dataframe of the scraped data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3678283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dad9e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the webdriver\n",
    "driver1=webdriver.Chrome()\n",
    "driver1.get(\"https://www.naukri.com/\")\n",
    "\n",
    "\n",
    "role=driver1.find_element(By.XPATH,'/html/body/div[1]/div[7]/div/div/div[1]/div/div/div/div[1]/div/input')\n",
    "role.send_keys(\"Data Scientist\")\n",
    "\n",
    "\n",
    "role_search=driver1.find_element(By.XPATH,'/html/body/div[1]/div[7]/div/div/div[6]')\n",
    "role_search.click()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37a06d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_filter = driver1.find_element(By.XPATH, '/html/body/div/div/main/div[1]/div[1]/div/div/div[2]/div[6]/div[2]/div[3]/label/p/span[1]')\n",
    "location_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dc6e00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_filter=driver1.find_element(By.XPATH,'/html/body/div/div/main/div[1]/div[1]/div/div/div[2]/div[3]/div[2]/div[2]/label/p/span[1]')\n",
    "salary_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d6d833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "exp_req=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00e3161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver1.find_elements(By.XPATH,'//div[@class=\"cust-job-tuple layout-wrapper lay-2 sjw__tuple \"]/div[1]')\n",
    "\n",
    "for i in title_tags:\n",
    "    job_title.append(i.text)\n",
    "    \n",
    "\n",
    "loc_tags=driver1.find_elements(By.XPATH,'//span[@class=\"locWdth\"]')\n",
    "\n",
    "for i in loc_tags:\n",
    "    job_location.append(i.text)\n",
    "    \n",
    "\n",
    "company_tags=driver1.find_elements(By.XPATH,'//div[@class=\" row2\"]/span/a[1]')\n",
    "\n",
    "for i in company_tags:\n",
    "    company_name.append(i.text)\n",
    "    \n",
    "    \n",
    "exp_tags=driver1.find_elements(By.XPATH,'//span[@class=\"expwdth\"]')\n",
    "\n",
    "for i in exp_tags:\n",
    "    exp_req.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec4bd717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(exp_req))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12315cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame({\"Job_title\":job_title,\"Job_location\":job_location,\"Company_name\":company_name,\"Experience_req\":exp_req})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa26aa90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience_req</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist HTHD</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>Ford</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mumbai, Hyderabad, Gurugram</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurugram, Bengaluru</td>\n",
       "      <td>Blackbuck</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Elitefit.ai</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>Fort Technologies</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lead Customer Success - Data Scientist</td>\n",
       "      <td>Pune, Gurugram</td>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>JOB Opening // Data science // Neosoft Mumbai ...</td>\n",
       "      <td>Noida, Mumbai, Pune</td>\n",
       "      <td>NeoSOFT</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Innovaccer</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Times Internet</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Python and ML Trainer</td>\n",
       "      <td>Hyderabad, New Delhi, Pune, Gurugram, Bengaluru</td>\n",
       "      <td>The Scholar</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurugram, Bengaluru</td>\n",
       "      <td>Acenet</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Varanasi, Kannur, Mumbai, New Delhi</td>\n",
       "      <td>Searchurcollege</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Insider Biz</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurugram</td>\n",
       "      <td>Gartner</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Pune, Gurugram</td>\n",
       "      <td>Gforce Consulting Solutions</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Ghaziabad, Uttar Pradesh(Vaishali)</td>\n",
       "      <td>Kreate Energy</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Dignitas Digital Pvt. Ltd</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Research Scientist - Bioinformatics</td>\n",
       "      <td>Gurugram</td>\n",
       "      <td>Biopeople India</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Analyst-Data Science</td>\n",
       "      <td>Gurugram</td>\n",
       "      <td>Resy</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Scientist - Data and Analytics (DNA)</td>\n",
       "      <td>Gurugram</td>\n",
       "      <td>Marsh McLennan</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job_title  \\\n",
       "0                                 Data Scientist HTHD   \n",
       "1                                      Data Scientist   \n",
       "2                                      Data Scientist   \n",
       "3                                 Lead Data Scientist   \n",
       "4                                      Data Scientist   \n",
       "5              Lead Customer Success - Data Scientist   \n",
       "6   JOB Opening // Data science // Neosoft Mumbai ...   \n",
       "7                                      Data Scientist   \n",
       "8                                      Data Scientist   \n",
       "9                               Python and ML Trainer   \n",
       "10                                     Data Scientist   \n",
       "11                                     Data Scientist   \n",
       "12                                     Data Scientist   \n",
       "13                                     Data Scientist   \n",
       "14                                     Data Scientist   \n",
       "15                                     Data Scientist   \n",
       "16                                    Data Scientists   \n",
       "17                Research Scientist - Bioinformatics   \n",
       "18                               Analyst-Data Science   \n",
       "19          Data Scientist - Data and Analytics (DNA)   \n",
       "\n",
       "                                         Job_location  \\\n",
       "0   Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...   \n",
       "1                         Mumbai, Hyderabad, Gurugram   \n",
       "2                                 Gurugram, Bengaluru   \n",
       "3   Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...   \n",
       "4   Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...   \n",
       "5                                      Pune, Gurugram   \n",
       "6                                 Noida, Mumbai, Pune   \n",
       "7                                               Noida   \n",
       "8                                               Noida   \n",
       "9     Hyderabad, New Delhi, Pune, Gurugram, Bengaluru   \n",
       "10                                Gurugram, Bengaluru   \n",
       "11                Varanasi, Kannur, Mumbai, New Delhi   \n",
       "12                                          New Delhi   \n",
       "13                                           Gurugram   \n",
       "14                            Kolkata, Pune, Gurugram   \n",
       "15                 Ghaziabad, Uttar Pradesh(Vaishali)   \n",
       "16                                          New Delhi   \n",
       "17                                           Gurugram   \n",
       "18                                           Gurugram   \n",
       "19                                           Gurugram   \n",
       "\n",
       "                   Company_name Experience_req  \n",
       "0                          Ford        1-4 Yrs  \n",
       "1                      Deloitte        3-6 Yrs  \n",
       "2                     Blackbuck        3-7 Yrs  \n",
       "3                   Elitefit.ai        3-7 Yrs  \n",
       "4             Fort Technologies        1-3 Yrs  \n",
       "5                 ZS Associates        2-4 Yrs  \n",
       "6                       NeoSOFT        4-7 Yrs  \n",
       "7                    Innovaccer        2-7 Yrs  \n",
       "8                Times Internet        3-8 Yrs  \n",
       "9                   The Scholar        3-8 Yrs  \n",
       "10                       Acenet        3-4 Yrs  \n",
       "11              Searchurcollege        1-3 Yrs  \n",
       "12                  Insider Biz        2-4 Yrs  \n",
       "13                      Gartner        3-6 Yrs  \n",
       "14  Gforce Consulting Solutions        3-8 Yrs  \n",
       "15                Kreate Energy        2-4 Yrs  \n",
       "16    Dignitas Digital Pvt. Ltd        2-5 Yrs  \n",
       "17              Biopeople India        0-2 Yrs  \n",
       "18                         Resy        0-3 Yrs  \n",
       "19               Marsh McLennan        0-5 Yrs  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eff004",
   "metadata": {},
   "source": [
    "#Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the \n",
    "job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.shine.com/\n",
    "2. Enter “Data Analyst” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the searchbutton. \n",
    "4. Then scrape the data for the first 10 jobs results you get. \n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f911b6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de64d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver1=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77ad5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver1.get(\"https://www.shine.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d17f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "role=driver1.find_element(By.CLASS_NAME,\"form-control  \")\n",
    "driver1.execute_script(\"arguments[0].value='Data Analyst';\",role)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcccd2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "area=driver1.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input\")\n",
    "area.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116d9bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "search1=driver1.find_element(By.XPATH,'/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[2]/div/button')\n",
    "search1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d79a390",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "exp_req=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef82a116",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver1.find_elements(By.XPATH,'//h2[@itemprop=\"name\"]/a')\n",
    "for i in title_tags:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "    \n",
    "location_tags=driver1.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in location_tags:\n",
    "    loc=i.text\n",
    "    job_location.append(loc)\n",
    "    \n",
    "company_tags=driver1.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]/span')\n",
    "for i in company_tags:\n",
    "    comp=i.text\n",
    "    company_name.append(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8138b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_tags=driver1.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for i in experience_tags:\n",
    "    term=i.text\n",
    "    exp_req.append(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0520f682",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(exp_req))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597470de",
   "metadata": {},
   "outputs": [],
   "source": [
    "shine_job_df=pd.DataFrame({'Job-title':job_title,'Job-location':job_location,'Company-name':company_name,'Experience-required':exp_req})\n",
    "\n",
    "shine_job_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09d77a5",
   "metadata": {},
   "source": [
    "Q3: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: \n",
    "https://www.flipkart.com/apple-iphone-15-black-128-gb/p/itm6ac6485515ae4?pid=MOBGTAGPTB3VS24W&lid=LSTMOBGTAGPTB3VS24WVZNSC6&marketplace=FLIPKART&q=iphone+15&store=tyy/4io&srno=s_1_2&otracker=AS_QueryStore_OrganicAutoSuggest_1_2_na_na_na&otracker1=AS_QueryStore_OrganicAutoSuggest_1_2_na_na_na&fm=organic&iid=b596c120-8114-44e8-9819-0b4dee130fa9.MOBGTAGPTB3VS24W.SEARCH&ppt=hp&ppn=homepage&ssid=s3c8i7dsvk0000001710403029549&qH=2f54b45b321e3ae5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4332ba",
   "metadata": {},
   "source": [
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews.\n",
    "Note: All the stepsrequired during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "298fb928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, WebDriverException\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9830c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver3=webdriver.Chrome()\n",
    "driver3.get(\"https://www.flipkart.com/apple-iphone-15-black-128-gb/p/itm6ac6485515ae4?pid=MOBGTAGPTB3VS24W&lid=LSTMOBGTAGPTB3VS24WVZNSC6&marketplace=FLIPKART&q=iphone+15&store=tyy/4io&srno=s_1_2&otracker=AS_QueryStore_OrganicAutoSuggest_1_2_na_na_na&otracker1=AS_QueryStore_OrganicAutoSuggest_1_2_na_na_na&fm=organic&iid=b596c120-8114-44e8-9819-0b4dee130fa9.MOBGTAGPTB3VS24W.SEARCH&ppt=hp&ppn=homepage&ssid=s3c8i7dsvk0000001710403029549&qH=2f54b45b321e3ae5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea43f5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_review=driver3.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[7]/div/a/div/span')\n",
    "all_review.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11064883",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_summary=[]\n",
    "\n",
    "start=0\n",
    "end=10\n",
    "\n",
    "for page in range(start,end):\n",
    "    try:\n",
    "        summary_tags=driver3.find_elements(By.XPATH,'//div[@class=\"col _2wzgFH K0kLPL\"]/div/p')\n",
    "        for i in summary_tags:\n",
    "            review_summary.append(i.text)\n",
    "    except NoSuchElementException as e:\n",
    "        print(\"NoSuchElementException\",e)\n",
    "    except WebDriverException as e:\n",
    "        print(\"WebDriverException\",e)\n",
    "    try:\n",
    "        next_page=driver3.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[11]/span')\n",
    "        next_page.click()\n",
    "    except NoSuchElementException as e:\n",
    "        print(\"NoSuchElementException\",e)\n",
    "    except WebDriverException as e:\n",
    "        print(\"WebDriverException\",e)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa5a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings=[]\n",
    "\n",
    "start=0\n",
    "end=10\n",
    "\n",
    "for page in range(start,end):\n",
    "    try:\n",
    "        rating_tags=driver3.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "        for i in rating_tags:\n",
    "            ratings.append(i.text)\n",
    "    except NoSuchElementException as e:\n",
    "        print(\"NoSuchElementException\",e)\n",
    "    except WebDriverException as e:\n",
    "        print(\"WebDriverException\",e)\n",
    "    try:\n",
    "        next_page=driver3.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[11]/span')\n",
    "        next_page.click()\n",
    "    except NoSuchElementException as e:\n",
    "        print(\"NoSuchElementException\",e)\n",
    "    except WebDriverException as e:\n",
    "        print(\"WebDriverException\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228ca78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_review=[]\n",
    "\n",
    "start=0\n",
    "end=10\n",
    "\n",
    "for page in range(start,end):\n",
    "    try:\n",
    "        full_tags=driver3.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]/div')\n",
    "        for i in full_tags:\n",
    "            full_review.append(i.text)\n",
    "    except NoSuchElementException as e:\n",
    "        print(\"NoSuchElementException\",e)\n",
    "    except WebDriverException as e:\n",
    "        print(\"WebDriverException\",e)\n",
    "    try:\n",
    "        next_page=driver3.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[11]/span')\n",
    "        next_page.click()\n",
    "    except NoSuchElementException as e:\n",
    "        print(\"NoSuchElementException\",e)\n",
    "    except WebDriverException as e:\n",
    "        print(\"WebDriverException\",e)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179570d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(review_summary),len(full_review),len(ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4664f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=pd.DataFrame({\"Ratings\":ratings,\"Review_summary\":review_summary,\"Full_review\":full_review})\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e3061e",
   "metadata": {},
   "source": [
    "Q4: Scrape data forfirst 100 sneakers you find whenyouvisitflipkart.com and search for “sneakers” inthe search\n",
    "field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the above attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39e4b74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1da295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver4=webdriver.Chrome()\n",
    "driver4.get(\" https://www.flipkart.com/\")\n",
    "\n",
    "product=driver4.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/div[1]/header/div[1]/div[2]/form/div/div/input')\n",
    "product.send_keys('sneakers')\n",
    "\n",
    "search=driver4.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/div[1]/header/div[1]/div[2]/form/div/button')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "213e93ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WebDriverException Message: disconnected: not connected to DevTools\n",
      "  (failed to check if window was closed: disconnected: not connected to DevTools)\n",
      "  (Session info: chrome=122.0.6261.112)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF69E9DAD32+56930]\n",
      "\t(No symbol) [0x00007FF69E94F632]\n",
      "\t(No symbol) [0x00007FF69E8042E5]\n",
      "\t(No symbol) [0x00007FF69E7F191F]\n",
      "\t(No symbol) [0x00007FF69E7F1490]\n",
      "\t(No symbol) [0x00007FF69E806411]\n",
      "\t(No symbol) [0x00007FF69E8878B9]\n",
      "\t(No symbol) [0x00007FF69E86BA43]\n",
      "\t(No symbol) [0x00007FF69E83D438]\n",
      "\t(No symbol) [0x00007FF69E83E4D1]\n",
      "\tGetHandleVerifier [0x00007FF69ED56ABD+3709933]\n",
      "\tGetHandleVerifier [0x00007FF69EDAFFFD+4075821]\n",
      "\tGetHandleVerifier [0x00007FF69EDA818F+4043455]\n",
      "\tGetHandleVerifier [0x00007FF69EA79766+706710]\n",
      "\t(No symbol) [0x00007FF69E95B90F]\n",
      "\t(No symbol) [0x00007FF69E956AF4]\n",
      "\t(No symbol) [0x00007FF69E956C4C]\n",
      "\t(No symbol) [0x00007FF69E946904]\n",
      "\tBaseThreadInitThunk [0x00007FFD9A9A7344+20]\n",
      "\tRtlUserThreadStart [0x00007FFD9AB826B1+33]\n",
      "\n",
      "WebDriverException Message: disconnected: not connected to DevTools\n",
      "  (failed to check if window was closed: disconnected: not connected to DevTools)\n",
      "  (Session info: chrome=122.0.6261.112)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF69E9DAD32+56930]\n",
      "\t(No symbol) [0x00007FF69E94F632]\n",
      "\t(No symbol) [0x00007FF69E8042E5]\n",
      "\t(No symbol) [0x00007FF69E7F191F]\n",
      "\t(No symbol) [0x00007FF69E7F1490]\n",
      "\t(No symbol) [0x00007FF69E806411]\n",
      "\t(No symbol) [0x00007FF69E8878B9]\n",
      "\t(No symbol) [0x00007FF69E86BA43]\n",
      "\t(No symbol) [0x00007FF69E83D438]\n",
      "\t(No symbol) [0x00007FF69E83E4D1]\n",
      "\tGetHandleVerifier [0x00007FF69ED56ABD+3709933]\n",
      "\tGetHandleVerifier [0x00007FF69EDAFFFD+4075821]\n",
      "\tGetHandleVerifier [0x00007FF69EDA818F+4043455]\n",
      "\tGetHandleVerifier [0x00007FF69EA79766+706710]\n",
      "\t(No symbol) [0x00007FF69E95B90F]\n",
      "\t(No symbol) [0x00007FF69E956AF4]\n",
      "\t(No symbol) [0x00007FF69E956C4C]\n",
      "\t(No symbol) [0x00007FF69E946904]\n",
      "\tBaseThreadInitThunk [0x00007FFD9A9A7344+20]\n",
      "\tRtlUserThreadStart [0x00007FFD9AB826B1+33]\n",
      "\n",
      "WebDriverException Message: disconnected: not connected to DevTools\n",
      "  (failed to check if window was closed: disconnected: not connected to DevTools)\n",
      "  (Session info: chrome=122.0.6261.112)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF69E9DAD32+56930]\n",
      "\t(No symbol) [0x00007FF69E94F632]\n",
      "\t(No symbol) [0x00007FF69E8042E5]\n",
      "\t(No symbol) [0x00007FF69E7F191F]\n",
      "\t(No symbol) [0x00007FF69E7F1490]\n",
      "\t(No symbol) [0x00007FF69E806411]\n",
      "\t(No symbol) [0x00007FF69E8878B9]\n",
      "\t(No symbol) [0x00007FF69E86BA43]\n",
      "\t(No symbol) [0x00007FF69E83D438]\n",
      "\t(No symbol) [0x00007FF69E83E4D1]\n",
      "\tGetHandleVerifier [0x00007FF69ED56ABD+3709933]\n",
      "\tGetHandleVerifier [0x00007FF69EDAFFFD+4075821]\n",
      "\tGetHandleVerifier [0x00007FF69EDA818F+4043455]\n",
      "\tGetHandleVerifier [0x00007FF69EA79766+706710]\n",
      "\t(No symbol) [0x00007FF69E95B90F]\n",
      "\t(No symbol) [0x00007FF69E956AF4]\n",
      "\t(No symbol) [0x00007FF69E956C4C]\n",
      "\t(No symbol) [0x00007FF69E946904]\n",
      "\tBaseThreadInitThunk [0x00007FFD9A9A7344+20]\n",
      "\tRtlUserThreadStart [0x00007FFD9AB826B1+33]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException, WebDriverException\n",
    "\n",
    "brand=[]\n",
    "\n",
    "start=0\n",
    "end=3\n",
    "\n",
    "for page in range(start,end):\n",
    "    try:\n",
    "        companies=driver4.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "        for company in companies:\n",
    "            brand.append(company.text)\n",
    "    except NoSuchElementException as e:\n",
    "        print(\"NoSuchElementException\",e)\n",
    "    except WebDriverException as e:\n",
    "        print(\"WebDriverException\",e)\n",
    "    try:\n",
    "        next_button1=driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]')\n",
    "        next_button1.click()\n",
    "        time.sleep(3)\n",
    "    except NoSuchElementException as e:\n",
    "        print(\"NoSuchElementException\",e)\n",
    "    except WebDriverException as e:\n",
    "        print(\"WebDriverException\",e)\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "97e242f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException, WebDriverException\n",
    "\n",
    "product_description=[]\n",
    "\n",
    "start=0\n",
    "end=3\n",
    "\n",
    "for page in range(start,end):\n",
    "    try:\n",
    "        products=driver4.find_elements(By.XPATH,'//div[@class=\"_2B099V\"]/a[1]')\n",
    "        for product in products:\n",
    "            product_description.append(product.text)\n",
    "    except NoSuchElementException as e:\n",
    "        print(\"NoSuchElementException\",e)\n",
    "    except WebDriverException as e:\n",
    "        print(\"WebDriverExcepton\",e)\n",
    "    try:\n",
    "        next_button2=driver4.find_element(By.XPATH,'/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]')\n",
    "        next_button2.click()\n",
    "        time.sleep(3)\n",
    "    except NoSuchElementException as e:\n",
    "        print(\"NoSuchElementException\",e)\n",
    "    except WebDriverException as e:\n",
    "        print(\"WebDriverException\",e)\n",
    "        \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "64e7d260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException, WebDriverException\n",
    "\n",
    "\n",
    "price=[]\n",
    "\n",
    "start =0\n",
    "end =3\n",
    "\n",
    "for page in range(start,end):\n",
    "    try:\n",
    "        prices=driver4.find_elements(By.XPATH,'//a[@class=\"_3bPFwb\"]/div/div[1]')\n",
    "        for cost in prices:\n",
    "            price.append(cost.text)\n",
    "    except NoSuchElementException as e:\n",
    "        print(\"NoSuchElementException\",e)\n",
    "    except WebDriverException as e:\n",
    "        print(\"WebDriverException\",e)\n",
    "    try:\n",
    "        next_button=driver4.find_element(By.XPATH,'/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]')\n",
    "        next_button.click()\n",
    "        time.sleep(3)\n",
    "    except NoSuchElementException as e:\n",
    "        print(\"NoSuchElementException\",e)\n",
    "    except WebDriverException as e:\n",
    "        print(\"WebDriverException\",e)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d47b64b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2 Combo Sneaker Shoes Sneakers For Men',\n",
       " 'Combo pack of 2 Trendy Sneaker Shoes Walking Shoes Snea...',\n",
       " 'Trending Stylish Casual Outdoor Shoes For Men Sneakers ...',\n",
       " 'Sneakers For Women',\n",
       " 'Casual Sneakers Shoes for Men | Soft Cushioned Insole, ...',\n",
       " 'Fire Run V1 Sneakers For Men',\n",
       " 'Trendy | Sport |Fashion Sneaker | Gym | Running Shoe Sn...',\n",
       " 'Combo Pack Of 2 Casual Shoes Sneakers For Men',\n",
       " 'Ultralightweight Premium Comfort Trendy Outdoor shoes f...',\n",
       " 'Premium Casual Shoes for Women Sneakers For Women',\n",
       " 'casual Sneakers For Men',\n",
       " 'Lightweight,Comfort,Summer,Trendy,Walking,Outdoor,Styli...',\n",
       " 'Sneaker Casual Shoes For Men | Soft Cushion Insole, Sli...',\n",
       " 'Combo Pack of 2 Casual Shoes Sneakers For Men',\n",
       " 'Casual & Trendy Sneakers For Men',\n",
       " 'Sneaker Casual Shoes For Men | Soft Cushion Insole, Sli...',\n",
       " 'Combo Pack Of 2 Casual Shoes Sneakers For Men',\n",
       " 'Combo Pack Of 2 Casual Shoes for mens Sneakers For Men',\n",
       " 'Combo pack of 2 shoes for men Sneakers For Men',\n",
       " 'Sneakers For Men',\n",
       " '2 Combo Shoes Sneakers For Men',\n",
       " 'Combo Pack Of 2 Casual Shoes Sneakers For Men',\n",
       " 'Synthetic Leather |Lightweight|Comfort|Summer|Trendy|Wa...',\n",
       " 'Premium Men Casual Shoes For Men Pack Of 2 Sneakers For...',\n",
       " 'Casual Sneakers Shoes for Men | Soft Cushioned Insole, ...',\n",
       " 'Sneakers For Men',\n",
       " '!Combo Pack Of 2 Casual Shoes! Sneakers For Men',\n",
       " 'Combo Pack Of 4 Casual Shoes Loafer Shoes Sneakers For ...',\n",
       " 'Combo Pack of 2 Casual Shoes Sneakers For Men',\n",
       " 'Casual Sneakers ColourFul Block Shoes For Boys And Men ...',\n",
       " 'Modern Trendy Sneakers Shoes Sneakers For Men',\n",
       " 'Sneakers For Men',\n",
       " 'Boston-01 Chunky Sneakers,Loafers,Walking Shoes Sneaker...',\n",
       " 'Tarzan-05 White Sneakers,Casuals,Loafers,Stylish With E...',\n",
       " 'Seattle Sneakers For Men',\n",
       " 'Premium Casual Shoes for Women Sneakers For Women',\n",
       " 'Combo Pack Of 2 Casual Shoes Sneakers For Men',\n",
       " '2 Combo Sneaker Shoes Sneakers For Men',\n",
       " 'Canvas shoes for Men Sneakers For Men',\n",
       " 'Carnival-02 Mens High Top Casual Chunky Sneakers For Me...',\n",
       " 'Sneaker Casual Shoes for Men | Soft Cushioned Insole, S...',\n",
       " 'Sneakers For Men',\n",
       " 'Stylish Sneakers Shoes for Women And Girls Sneakers For...',\n",
       " 'Sneakers For Men',\n",
       " 'Shuffle Ultra Sneakers For Men',\n",
       " 'PANAL Sneakers For Men',\n",
       " 'Premium Sports Shoes For Men Pack Of 2 Sneakers For Men',\n",
       " 'Casual Stylish Trending Sneakers For Women',\n",
       " 'Rebound Future NextGen Sneakers For Men',\n",
       " 'Seattle Sneakers For Men',\n",
       " 'HIGH HEEL SHOES Sneakers For Women',\n",
       " 'Seattle Sneakers For Men',\n",
       " 'Thunder-01 White Canvas, Sneakers For Men',\n",
       " 'Sneaker Casual Shoes For Men | Soft Cushion Insole || B...',\n",
       " 'Casual Sneakers White Shoes For Girls And Sneakers For ...',\n",
       " 'Ferrari Electron E Pro Sneakers For Men',\n",
       " 'Stylish Casual Sports Shoe Sneakers Sneakers For Women',\n",
       " 'SM-671 Sneakers For Men',\n",
       " 'Sneakers For Men',\n",
       " 'Sports Shoes , Walking Shoes , Gym & Training Shoes And...',\n",
       " 'Premium Casual Shoes for Women Sneakers For Women',\n",
       " 'Sneakers For Men',\n",
       " 'FAST Trendy Sneakers For Men',\n",
       " 'Colourful Block Shoes For Boys Casual Sneakers For Men',\n",
       " 'Casual Sneaker Shoes for Men | Soft Cushioned Insole, S...',\n",
       " 'OG-D4 Sneakers For Men',\n",
       " 'Sneakers For Men',\n",
       " 'Trendy & Stylish Sneakers For Men',\n",
       " 'Sneaker Casual Shoes for Men | Soft Cushioned Insole, S...',\n",
       " 'Sneaker Casual Shoes for Men | Soft Cushioned Insole, S...',\n",
       " 'Carnival-02 Mens High Top Casual Chunky Sneakers Sneake...',\n",
       " 'FORUM 84 LOW Sneakers For Men',\n",
       " 'PANAL Sneakers For Men',\n",
       " 'Caven Sneakers For Men',\n",
       " \"Sneaker Shoes For Men's - Elevated Comfort, Perfect Cas...\",\n",
       " 'Seattle Sneakers For Men',\n",
       " 'Casual Sneakers Colour Blocked Shoes For Boys And Men S...',\n",
       " 'LEBRON 3.0 Sneakers For Men',\n",
       " 'Sneakers For Women',\n",
       " 'Sneaker Casual Shoes For Men | Soft Cushion Insole, Sli...',\n",
       " 'TYLOR Sneakers For Men',\n",
       " 'Sneakers For Men',\n",
       " 'Lifestyle Sneaker Shoes for Men | Soft Cushioned Insole...',\n",
       " 'Casual Sneaker Shoes for Men | Soft Cushioned Insole, S...',\n",
       " 'Capri Royale Sneakers For Men',\n",
       " 'Alfarun Sneakers For Men',\n",
       " 'Sneaker Casual Shoes For Men | Soft Cushion Insole, Sli...',\n",
       " 'Stylish Casual Sports Shoe Sneakers Sneakers For Women',\n",
       " 'Flat Sole Sneakers Shoes for all Day wear with Memory C...',\n",
       " 'FITZ 2.0 Sneakers For Men',\n",
       " 'NEO MOTORSPORT Sneakers For Men',\n",
       " 'ALFONSO Sneakers For Men',\n",
       " 'Men 192 Sneakers For Men',\n",
       " \"Newton-01 Men's Lightweight Running Shoes Sneakers For ...\",\n",
       " 'RHEECE Sneakers For Men',\n",
       " '550 Sneakers For Men',\n",
       " '574 Sneakers For Men',\n",
       " 'Court Ultra Lite Sneakers For Men',\n",
       " 'Lifestyle Sneaker Shoes for Men | Soft Cushioned Insole...',\n",
       " 'Sneakers For Men',\n",
       " 'CLARKIN Sneakers For Men',\n",
       " '439 Sneakers For Men',\n",
       " 'Sneakers For Men',\n",
       " 'Pacer Future Trail Sneakers For Men',\n",
       " 'Sneakers For Men',\n",
       " 'GEL-CITREK Sneakers For Men',\n",
       " 'Combo Pack of 2 Casual Shoe Sneakers For Men',\n",
       " '( by GO21 ) Soft Insole, Slip-Resistance|Walking Casual...',\n",
       " 'Sneakers For Men',\n",
       " 'Casual Sneaker Shoes For Women | Stylish and Comfortabl...',\n",
       " 'Stride FS Sneakers For Men',\n",
       " 'R78 Sneakers For Men',\n",
       " 'Rebound v6 Sneakers For Men',\n",
       " 'ST Runner v3 L Sneakers For Men',\n",
       " 'X-Ray 2 Square Sneakers For Men',\n",
       " 'CAPRON 2.0 Sneakers For Men',\n",
       " 'Sneakers For Women',\n",
       " 'MOTORSPORTS LEGACY Sneakers For Men',\n",
       " 'Neo Motorsport Sneakers For Men',\n",
       " 'Lifestyle Sneaker Shoes for Women | Soft Cushioned Inso...']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0cb9462e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>2 Combo Sneaker Shoes Sneakers For Men</td>\n",
       "      <td>₹346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Combo pack of 2 Trendy Sneaker Shoes Walking S...</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>Trending Stylish Casual Outdoor Shoes For Men ...</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>Casual Sneakers Shoes for Men | Soft Cushioned...</td>\n",
       "      <td>₹1,179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>asian</td>\n",
       "      <td>CAPRON 2.0 Sneakers For Men</td>\n",
       "      <td>₹849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>CCICACO</td>\n",
       "      <td>MOTORSPORTS LEGACY Sneakers For Men</td>\n",
       "      <td>₹795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>asian</td>\n",
       "      <td>Neo Motorsport Sneakers For Men</td>\n",
       "      <td>₹6,249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Lifestyle Sneaker Shoes for Women | Soft Cushi...</td>\n",
       "      <td>₹3,044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Brand                                Product_description   Price\n",
       "0       BRUTON             2 Combo Sneaker Shoes Sneakers For Men    ₹346\n",
       "1       BRUTON  Combo pack of 2 Trendy Sneaker Shoes Walking S...    ₹499\n",
       "2     URBANBOX  Trending Stylish Casual Outdoor Shoes For Men ...    ₹299\n",
       "3    Deals4you                                 Sneakers For Women    ₹439\n",
       "4     RED TAPE  Casual Sneakers Shoes for Men | Soft Cushioned...  ₹1,179\n",
       "..         ...                                                ...     ...\n",
       "115      asian                        CAPRON 2.0 Sneakers For Men    ₹849\n",
       "116     BRUTON                                 Sneakers For Women    ₹746\n",
       "117    CCICACO                MOTORSPORTS LEGACY Sneakers For Men    ₹795\n",
       "118      asian                    Neo Motorsport Sneakers For Men  ₹6,249\n",
       "119      BIRDE  Lifestyle Sneaker Shoes for Women | Soft Cushi...  ₹3,044\n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4=pd.DataFrame({\"Brand\":brand,\"Product_description\":product_description,\"Price\":price})\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "52e565f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120\n"
     ]
    }
   ],
   "source": [
    "print(len(brand),len(product_description),len(price))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7d49c1",
   "metadata": {},
   "source": [
    "Q5: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU\n",
    "Type filter to “Intel Core i7” as shown in the below image:\n",
    "Aftersetting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "035cf1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, WebDriverException\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cf568fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver5=webdriver.Chrome()\n",
    "driver5.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6de80288",
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop=driver5.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "laptop.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b77ab6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_icon=driver5.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "search_icon.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "46852952",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_click=driver5.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[19]/span/span[11]/li/span/a/span')\n",
    "cpu_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e323c8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop_title=[]\n",
    "\n",
    "title=driver5.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "\n",
    "for titles in title:\n",
    "    laptop_title.append(titles.text)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4db1b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "value=[]\n",
    "\n",
    "field=driver5.find_elements(By.XPATH,'//div[@class=\"a-row a-size-small\"]')\n",
    "\n",
    "for fields in field:\n",
    "    value.append(fields.text)\n",
    " \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1e48a7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "price=[]\n",
    "\n",
    "prices=driver5.find_elements(By.XPATH,'//span[@class=\"a-price\"]')\n",
    "\n",
    "for cost in prices:\n",
    "    price.append(cost.text)\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dd8e7438",
   "metadata": {},
   "outputs": [],
   "source": [
    "price=price[:10]\n",
    "value=value[:10]\n",
    "laptop_title=laptop_title[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ec7af551",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5=pd.DataFrame({\"Laptop_title\":laptop_title,\"Ratings\":value,\"Price\":price})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "92d40813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop_title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 Intel Core i7 12th Gen 1...</td>\n",
       "      <td>459</td>\n",
       "      <td>₹62,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS Vivobook 15, Intel Core i7-12650H 12th Ge...</td>\n",
       "      <td>450</td>\n",
       "      <td>₹59,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSI Modern 14, Intel 12th Gen. i7-1255U, 36CM ...</td>\n",
       "      <td>88</td>\n",
       "      <td>₹49,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS TUF Gaming F15, 15.6\"(39.62 cms) FHD 144H...</td>\n",
       "      <td>227</td>\n",
       "      <td>₹74,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acer Travelmate Business Laptop Intel Core i7-...</td>\n",
       "      <td>2</td>\n",
       "      <td>₹49,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo Yoga Slim7 Carbon Intel Evo i7 1260P 13...</td>\n",
       "      <td>4</td>\n",
       "      <td>₹1,19,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS Vivobook 15, Intel Core i7-12650H 12th Ge...</td>\n",
       "      <td>450</td>\n",
       "      <td>₹59,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dell G15 5530 Gaming Laptop, Intel i7-13650HX/...</td>\n",
       "      <td>1</td>\n",
       "      <td>₹1,04,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Pavilion X360 11th Gen Intel Core i7 14\" (3...</td>\n",
       "      <td>146</td>\n",
       "      <td>₹66,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP Victus Gaming Laptop, 12th Gen Intel Core i...</td>\n",
       "      <td>357</td>\n",
       "      <td>₹79,490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Laptop_title Ratings      Price\n",
       "0  Lenovo IdeaPad Slim 3 Intel Core i7 12th Gen 1...     459    ₹62,700\n",
       "1  ASUS Vivobook 15, Intel Core i7-12650H 12th Ge...     450    ₹59,990\n",
       "2  MSI Modern 14, Intel 12th Gen. i7-1255U, 36CM ...      88    ₹49,990\n",
       "3  ASUS TUF Gaming F15, 15.6\"(39.62 cms) FHD 144H...     227    ₹74,990\n",
       "4  Acer Travelmate Business Laptop Intel Core i7-...       2    ₹49,990\n",
       "5  Lenovo Yoga Slim7 Carbon Intel Evo i7 1260P 13...       4  ₹1,19,990\n",
       "6  ASUS Vivobook 15, Intel Core i7-12650H 12th Ge...     450    ₹59,990\n",
       "7  Dell G15 5530 Gaming Laptop, Intel i7-13650HX/...       1  ₹1,04,490\n",
       "8  HP Pavilion X360 11th Gen Intel Core i7 14\" (3...     146    ₹66,999\n",
       "9  HP Victus Gaming Laptop, 12th Gen Intel Core i...     357    ₹79,490"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b96093c",
   "metadata": {},
   "source": [
    "Q6: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "The above task will be done in following steps:\n",
    "1. First get the webpagehttps://www.azquotes.com/\n",
    "2. Click on TopQuote\n",
    "3. Than scrap a)Quote b) Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b9348557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "39d7fbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver6=webdriver.Chrome()\n",
    "driver6.get(\"https://www.azquotes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1911700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_quotes=driver6.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[5]/a')\n",
    "top_quotes.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "85727e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException, WebDriverException\n",
    "phrase=[]\n",
    "\n",
    "start=0\n",
    "end=10\n",
    "\n",
    "for page in range(start,end):\n",
    "    try:\n",
    "        phrases=driver6.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "        for i in phrases:\n",
    "            phrase.append(i.text)\n",
    "    except NoSuchElementException as e:\n",
    "        print(\"NoSuchElementException\",e)\n",
    "    except WebDriverException as e:\n",
    "        print(\"WebDriverException\",e)\n",
    "    try:\n",
    "        next_button=driver6.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[4]/li[12]/a')\n",
    "        next_button.click()\n",
    "    except NoSuchElementException as e:\n",
    "        print(\"NoSuchElementException\",e)\n",
    "    except WebDriverException as e:\n",
    "        print(\"WebDriverException\",e)\n",
    "\n",
    "    \n",
    "\n",
    "            \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "394e503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "author=[]\n",
    "\n",
    "start=0\n",
    "end=10\n",
    "\n",
    "for page in range(start,end):\n",
    "    try:\n",
    "        authors=driver6.find_elements(By.XPATH,'//div[@class=\"author\"]/a')\n",
    "        for i in authors:\n",
    "            author.append(i.text)\n",
    "    except NoSuchElementException as e:\n",
    "        print(\"NoSuchElementException\",e)\n",
    "    except WebDriverException as e:\n",
    "        print(\"WebDriverException\",e)\n",
    "    try:\n",
    "        next_button=driver6.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[4]/li[12]/a')\n",
    "        next_button.click()\n",
    "    except NoSuchElementException as e:\n",
    "        print(\"NoSuchElementException\",e)\n",
    "    except WebDriverException as e:\n",
    "        print(\"WebDriverException\",e)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e82896b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_genre=[]\n",
    "\n",
    "\n",
    "start=0\n",
    "end=10\n",
    "\n",
    "for page in range(start,end):\n",
    "    try:\n",
    "        genre=driver6.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "        for i in genre:\n",
    "            quote_genre.append(i.text)\n",
    "    except NoSuchElementException as e:\n",
    "        print(\"NoSuchElementException\",e)\n",
    "    except WebDriverException as e:\n",
    "        print(\"WebDriverException\",e)\n",
    "    try:\n",
    "        next_button=driver6.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[4]/li[12]/a')\n",
    "        next_button.click()\n",
    "    except NoSuchElementException as e:\n",
    "        print(\"NoSuchElementException\",e)\n",
    "    except WebDriverException as e:\n",
    "        print(\"WebDriverException\",e)\n",
    "        \n",
    "   \n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8b2daaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(quote_genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e99ab2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6=pd.DataFrame({\"Quotes\":phrase,\"Authors\":author,\"Types_of_quotes\":quote_genre})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a8a25344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quotes</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Types_of_quotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Spring, April, Fragrance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspirational, Faith, Spiritual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Inspirational, Motivational, Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Love, Inspirational, Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>Strength, Peace, Gun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Regret for the things we did can be tempered b...</td>\n",
       "      <td>Sydney J. Harris</td>\n",
       "      <td>Love, Inspirational, Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>America... just a nation of two hundred millio...</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Gun, Two, Qualms About</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>For every disciplined effort there is a multip...</td>\n",
       "      <td>Jim Rohn</td>\n",
       "      <td>Inspirational, Greatness, Best Effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The spiritual journey is individual, highly pe...</td>\n",
       "      <td>Ram Dass</td>\n",
       "      <td>Spiritual, Truth, Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>The mind is not a vessel to be filled but a fi...</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Inspirational, Leadership, Education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Quotes             Authors  \\\n",
       "0    The essence of strategy is choosing what not t...      Michael Porter   \n",
       "1    One cannot and must not try to erase the past ...          Golda Meir   \n",
       "2    Patriotism means to stand by the country. It d...  Theodore Roosevelt   \n",
       "3    Death is something inevitable. When a man has ...      Nelson Mandela   \n",
       "4    You have to love a nation that celebrates its ...        Erma Bombeck   \n",
       "..                                                 ...                 ...   \n",
       "995  Regret for the things we did can be tempered b...    Sydney J. Harris   \n",
       "996  America... just a nation of two hundred millio...  Hunter S. Thompson   \n",
       "997  For every disciplined effort there is a multip...            Jim Rohn   \n",
       "998  The spiritual journey is individual, highly pe...            Ram Dass   \n",
       "999  The mind is not a vessel to be filled but a fi...            Plutarch   \n",
       "\n",
       "                           Types_of_quotes  \n",
       "0                 Spring, April, Fragrance  \n",
       "1          Inspirational, Faith, Spiritual  \n",
       "2    Inspirational, Motivational, Positive  \n",
       "3                Love, Inspirational, Life  \n",
       "4                     Strength, Peace, Gun  \n",
       "..                                     ...  \n",
       "995      Love, Inspirational, Motivational  \n",
       "996                 Gun, Two, Qualms About  \n",
       "997  Inspirational, Greatness, Best Effort  \n",
       "998                 Spiritual, Truth, Yoga  \n",
       "999   Inspirational, Leadership, Education  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8dd18e",
   "metadata": {},
   "source": [
    "Q7: Write a python program to display list of respected former Prime Ministers of India (i.e. Name,\n",
    "Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/general-knowledge/list-of\u0002all-prime-ministers-of-india-1473165149-1\n",
    "scrap the mentioned data and make the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "823eec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, WebDriverException\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967d3cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver7=webdriver.Chrome()\n",
    "driver7.get(\"https://www.jagranjosh.com/general-knowledge/list-of\u0002all-prime-ministers-of-india-1473165149-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46796c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "table=[]\n",
    "\n",
    "table_tags=driver7.find_elements(By.CSS_SELECTOR,'td')\n",
    "for i in table_tags:\n",
    "    table.append(i.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0217b1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f861c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['S.no','Name', 'Born-Dead', 'Term of Office', 'Remarks']\n",
    "df = pd.DataFrame([table[i:i+5] for i in range(0, len(table), 5)], columns=columns)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af06571",
   "metadata": {},
   "source": [
    "Q8: Write a python program to display list of 50 Most expensive cars in the world (i.e. Car name and Price) from https://www.motor1.com/ This task will be done in following steps:\n",
    "\n",
    "First get the webpage https://www.motor1.com/\n",
    "Then You have to type in the search bar ’50 most expensive cars’\n",
    "Then click on 50 most expensive carsin the world..\n",
    "Then scrap thementioned data and make the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56797efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, WebDriverException\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f3e5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get(\" https://www.motor1.com/ \")\n",
    "\n",
    "\n",
    "car=driver.find_element(By.XPATH,'/html/body/div[9]/div[2]/div/div/div[3]/div/div/div/form/input')\n",
    "car.send_keys(\"50 most expensive cars\")\n",
    "\n",
    "car_search=driver.find_element(By.XPATH,'/html/body/div[9]/div[2]/div/div/div[3]/div/div/div/form/button[1]')\n",
    "car_search.click()\n",
    "\n",
    "expensive_car=driver.find_element(By.XPATH,'/html/body/div[9]/div[10]/div/div[1]/div/div/div[1]/div/div[1]/h3/a')\n",
    "expensive_car.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43df710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_name=[]\n",
    "\n",
    "\n",
    "name=driver.find_elements(By.XPATH,'//h3[@class=\"subheader\"]')\n",
    "\n",
    "for names in name:\n",
    "    car_name.append(names.text)\n",
    "    \n",
    "    \n",
    "    \n",
    "price=[]\n",
    "\n",
    "car_price=driver.find_elements(By.CSS_SELECTOR,'strong')\n",
    "\n",
    "for cost in car_price:\n",
    "    price.append(cost.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708daa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_name=car_name[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5993ab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(car_name),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a22aa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expensive_car=pd.DataFrame({\"Car_name\":car_name,\"Price\":price})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b813450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expensive_car"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
