{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94baa029",
   "metadata": {},
   "source": [
    "#1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url\n",
    "= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: A)\n",
    "Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "015d632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1474d0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "524a66e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "artist=[]\n",
    "upload_date=[]\n",
    "views=[]\n",
    "\n",
    "rank=list(range(1,31))\n",
    "       \n",
    "    \n",
    "name_element=driver.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[1]')\n",
    "for i in name_element:\n",
    "    name.append(i.text)\n",
    "    \n",
    "artist_element=driver.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[2]')\n",
    "for i in artist_element:\n",
    "    artist.append(i.text)\n",
    "    \n",
    "\n",
    "date_element=driver.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[4]')\n",
    "for i in date_element:\n",
    "    upload_date.append(i.text)\n",
    "    \n",
    "view_element=driver.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[3]')\n",
    "for i in view_element:\n",
    "    views.append(i.text)\n",
    "    \n",
    "    \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e97e839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video Name</th>\n",
       "      <th>Uploader</th>\n",
       "      <th>Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Baby Shark Dance\"[7]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>14.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"Despacito\"[10]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[18]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Bath Song\"[19]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"Shape of You\"[20]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>\"See You Again\"[23]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>6.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>\"Wheels on the Bus\"[28]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>6.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>\"Phonics Song with Two Words\"[29]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>\"Uptown Funk\"[30]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>5.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>5.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[36]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>5.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[38]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>\"Axel F\"[39]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>\"Sugar\"[40]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>4.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[41]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>4.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>\"Counting Stars\"[42]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[43]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>\"Roar\"[44]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[45]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>\"Sorry\"[46]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>\"Shree Hanuman Chalisa\"[47]</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>May 10, 2011</td>\n",
       "      <td>3.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[48]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>\"Thinking Out Loud\"[49]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>\"Perfect\"[50]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>\"Dark Horse\"[51]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>\"Let Her Go\"[52]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>\"Faded\"[53]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>\"Girls Like You\"[54]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>\"Lean On\"[55]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                                       Video Name  \\\n",
       "0      1                            \"Baby Shark Dance\"[7]   \n",
       "1      2                                  \"Despacito\"[10]   \n",
       "2      3                       \"Johny Johny Yes Papa\"[18]   \n",
       "3      4                                  \"Bath Song\"[19]   \n",
       "4      5                               \"Shape of You\"[20]   \n",
       "5      6                              \"See You Again\"[23]   \n",
       "6      7                          \"Wheels on the Bus\"[28]   \n",
       "7      8                \"Phonics Song with Two Words\"[29]   \n",
       "8      9                                \"Uptown Funk\"[30]   \n",
       "9     10                              \"Gangnam Style\"[31]   \n",
       "10    11  \"Learning Colors – Colorful Eggs on a Farm\"[36]   \n",
       "11    12                             \"Dame Tu Cosita\"[37]   \n",
       "12    13   \"Masha and the Bear – Recipe for Disaster\"[38]   \n",
       "13    14                                     \"Axel F\"[39]   \n",
       "14    15                                      \"Sugar\"[40]   \n",
       "15    16                        \"Baa Baa Black Sheep\"[41]   \n",
       "16    17                             \"Counting Stars\"[42]   \n",
       "17    18                             \"Lakdi Ki Kathi\"[43]   \n",
       "18    19                                       \"Roar\"[44]   \n",
       "19    20           \"Waka Waka (This Time for Africa)\"[45]   \n",
       "20    21                                      \"Sorry\"[46]   \n",
       "21    22                      \"Shree Hanuman Chalisa\"[47]   \n",
       "22    23          \"Humpty the train on a fruits ride\"[48]   \n",
       "23    24                          \"Thinking Out Loud\"[49]   \n",
       "24    25                                    \"Perfect\"[50]   \n",
       "25    26                                 \"Dark Horse\"[51]   \n",
       "26    27                                 \"Let Her Go\"[52]   \n",
       "27    28                                      \"Faded\"[53]   \n",
       "28    29                             \"Girls Like You\"[54]   \n",
       "29    30                                    \"Lean On\"[55]   \n",
       "\n",
       "                                             Uploader               Date  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                          Luis Fonsi   January 12, 2017   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs    October 8, 2016   \n",
       "3                          Cocomelon - Nursery Rhymes        May 2, 2018   \n",
       "4                                          Ed Sheeran   January 30, 2017   \n",
       "5                                         Wiz Khalifa      April 6, 2015   \n",
       "6                          Cocomelon - Nursery Rhymes       May 24, 2018   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs      March 6, 2014   \n",
       "8                                         Mark Ronson  November 19, 2014   \n",
       "9                                                 Psy      July 15, 2012   \n",
       "10                                        Miroshka TV  February 27, 2018   \n",
       "11                                      Ultra Records      April 5, 2018   \n",
       "12                                         Get Movies   January 31, 2012   \n",
       "13                                         Crazy Frog      June 16, 2009   \n",
       "14                                           Maroon 5   January 14, 2015   \n",
       "15                         Cocomelon - Nursery Rhymes      June 25, 2018   \n",
       "16                                        OneRepublic       May 31, 2013   \n",
       "17                                       Jingle Toons      June 14, 2018   \n",
       "18                                         Katy Perry  September 5, 2013   \n",
       "19                                            Shakira       June 4, 2010   \n",
       "20                                      Justin Bieber   October 22, 2015   \n",
       "21                              T-Series Bhakti Sagar       May 10, 2011   \n",
       "22      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "23                                         Ed Sheeran    October 7, 2014   \n",
       "24                                         Ed Sheeran   November 9, 2017   \n",
       "25                                         Katy Perry  February 20, 2014   \n",
       "26                                          Passenger      July 25, 2012   \n",
       "27                                        Alan Walker   December 3, 2015   \n",
       "28                                           Maroon 5       May 31, 2018   \n",
       "29                               Major Lazer Official     March 22, 2015   \n",
       "\n",
       "    Views  \n",
       "0   14.32  \n",
       "1    8.41  \n",
       "2    6.89  \n",
       "3    6.66  \n",
       "4    6.23  \n",
       "5    6.22  \n",
       "6    6.01  \n",
       "7    5.75  \n",
       "8    5.18  \n",
       "9    5.10  \n",
       "10   5.09  \n",
       "11   4.59  \n",
       "12   4.57  \n",
       "13   4.45  \n",
       "14   4.02  \n",
       "15   4.01  \n",
       "16   4.00  \n",
       "17   3.98  \n",
       "18   3.98  \n",
       "19   3.89  \n",
       "20   3.78  \n",
       "21   3.77  \n",
       "22   3.76  \n",
       "23   3.75  \n",
       "24   3.70  \n",
       "25   3.70  \n",
       "26   3.64  \n",
       "27   3.60  \n",
       "28   3.58  \n",
       "29   3.57  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_video=pd.DataFrame({\"Rank\":rank,\"Video Name\":name,\"Uploader\":artist,\"Date\":upload_date,\"Views\":views})\n",
    "\n",
    "df_video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4cd839",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Series\n",
    "B) Place\n",
    "C) Date\n",
    "D) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4dccbd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException  \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1b9536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "url = \"https://www.bcci.tv/\"\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "fixture=driver.find_element(By.XPATH,'/html/body/header/div[3]/div[2]/ul/div[1]/a[2]')\n",
    "fixture.click()\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "series=[]\n",
    "place=[]\n",
    "date=[]\n",
    "time_node=[]\n",
    "\n",
    "\n",
    "series_element=driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "for serie in series_element:\n",
    "    series.append(serie.text)\n",
    "    \n",
    "place_element=driver.find_elements(By.XPATH,'//div[@class=\"col-lg-6 col-md-6 col-sm-12\"]/div[1]')\n",
    "for places in place_element:\n",
    "    place.append(places.text)\n",
    "    \n",
    "date_element=driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')\n",
    "for dates in date_element:\n",
    "    date.append(dates.text)\n",
    "    \n",
    "    \n",
    "time_element=driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "for times in time_element:\n",
    "    time_node.append(times.text)\n",
    "    \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6eeefc29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>Nassau County International Cricket Stadium, N...</td>\n",
       "      <td>5 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>Nassau County International Cricket Stadium, N...</td>\n",
       "      <td>9 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>Nassau County International Cricket Stadium, N...</td>\n",
       "      <td>12 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>Central Broward Park &amp; Broward County Stadium,...</td>\n",
       "      <td>15 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>6 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>7 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>10 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>13 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>14 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Series  \\\n",
       "0  ICC MENS T20 WORLD CUP 2024   \n",
       "1  ICC MENS T20 WORLD CUP 2024   \n",
       "2  ICC MENS T20 WORLD CUP 2024   \n",
       "3  ICC MENS T20 WORLD CUP 2024   \n",
       "4  INDIA TOUR OF ZIMBABWE 2024   \n",
       "5  INDIA TOUR OF ZIMBABWE 2024   \n",
       "6  INDIA TOUR OF ZIMBABWE 2024   \n",
       "7  INDIA TOUR OF ZIMBABWE 2024   \n",
       "8  INDIA TOUR OF ZIMBABWE 2024   \n",
       "\n",
       "                                               Place           Date  \\\n",
       "0  Nassau County International Cricket Stadium, N...   5 JUNE, 2024   \n",
       "1  Nassau County International Cricket Stadium, N...   9 JUNE, 2024   \n",
       "2  Nassau County International Cricket Stadium, N...  12 JUNE, 2024   \n",
       "3  Central Broward Park & Broward County Stadium,...  15 JUNE, 2024   \n",
       "4                         Harare Sports Club, Harare   6 JULY, 2024   \n",
       "5                         Harare Sports Club, Harare   7 JULY, 2024   \n",
       "6                         Harare Sports Club, Harare  10 JULY, 2024   \n",
       "7                         Harare Sports Club, Harare  13 JULY, 2024   \n",
       "8                         Harare Sports Club, Harare  14 JULY, 2024   \n",
       "\n",
       "          Time  \n",
       "0  8:00 PM IST  \n",
       "1  8:00 PM IST  \n",
       "2  8:00 PM IST  \n",
       "3  8:00 PM IST  \n",
       "4  8:00 PM IST  \n",
       "5  8:00 PM IST  \n",
       "6  8:00 PM IST  \n",
       "7  8:00 PM IST  \n",
       "8  8:00 PM IST  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_match=pd.DataFrame({\"Series\":series,\"Place\":place,\"Date\":date,\"Time\":time_node})\n",
    "df_match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3828e345",
   "metadata": {},
   "source": [
    "3. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details: A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14493d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException,ElementNotInteractableException \n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8beca794",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "url = \"http://statisticstimes.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "\n",
    "economy=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]')\n",
    "economy.click()\n",
    "time.sleep(2)\n",
    "\n",
    "try:\n",
    "    eco_india=WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')))\n",
    "    eco_india.click()\n",
    "except ElementNotInteractableException  as e:\n",
    "    print(\"ElementNotInteractableException\",e)\n",
    "                                                                            \n",
    "                                                                            \n",
    "try:\n",
    "    gdp_element=WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')))\n",
    "    gdp_element.click()\n",
    "except TimeoutException as e:\n",
    "    print(\"TimeoutException \",e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "41925c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=[]\n",
    "state=[]\n",
    "gsdp_22_23_current_price=[]\n",
    "gsdp_23_24_current_price=[]\n",
    "share_21_22=[]\n",
    "gdp_billion=[]\n",
    "\n",
    "\n",
    "rank_element=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[1]')\n",
    "for ranks in rank_element:\n",
    "    if len(rank)<33:\n",
    "        rank.append(ranks.text)\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "    \n",
    "\n",
    "state_element=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[2]')\n",
    "for states in state_element:\n",
    "    if len(state)<33:\n",
    "        state.append(states.text)\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "gsdp_element_latest=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[3]')\n",
    "for latest in gsdp_element_latest:\n",
    "    if len(gsdp_23_24_current_price)<33:\n",
    "        gsdp_23_24_current_price.append(latest.text)\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "    \n",
    "    \n",
    "gsdp_element_previous=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[4]')\n",
    "for previous in gsdp_element_previous:\n",
    "    if len(gsdp_22_23_current_price)<33:\n",
    "        gsdp_22_23_current_price.append(previous.text)\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "\n",
    "share_element=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[6]')\n",
    "for shares in share_element:\n",
    "    if len(share_21_22)<33:\n",
    "        share_21_22.append(shares.text)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "time.sleep(2)\n",
    "    \n",
    "gdp_element=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[7]')\n",
    "for gdps in gdp_element:\n",
    "    if len(gdp_billion)<33:\n",
    "        gdp_billion.append(gdps.text)\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bd205fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Maharashtra',\n",
       " 'Tamil Nadu',\n",
       " 'Karnataka',\n",
       " 'Uttar Pradesh',\n",
       " 'Gujarat',\n",
       " 'West Bengal',\n",
       " 'Rajasthan',\n",
       " 'Andhra Pradesh',\n",
       " 'Telangana',\n",
       " 'Madhya Pradesh',\n",
       " 'Kerala',\n",
       " 'Delhi',\n",
       " 'Haryana',\n",
       " 'Odisha',\n",
       " 'Bihar',\n",
       " 'Punjab',\n",
       " 'Assam',\n",
       " 'Chhattisgarh',\n",
       " 'Jharkhand',\n",
       " 'Uttarakhand',\n",
       " 'Jammu & Kashmir',\n",
       " 'Himachal Pradesh',\n",
       " 'Goa',\n",
       " 'Tripura',\n",
       " 'Chandigarh',\n",
       " 'Puducherry',\n",
       " 'Meghalaya',\n",
       " 'Sikkim',\n",
       " 'Manipur',\n",
       " 'Arunachal Pradesh',\n",
       " 'Nagaland',\n",
       " 'Mizoram',\n",
       " 'Andaman & Nicobar Islands']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "10dab2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gdp=pd.DataFrame({\"Rank\":rank,\"State\":state,\"GSDP_23_24\":gsdp_23_24_current_price,\"GSDP_22_23\":gsdp_22_23_current_price,\"Share_21_22\":share_21_22,\"GDP_billion\":gdp_billion})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aeb2f94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP_23_24</th>\n",
       "      <th>GSDP_22_23</th>\n",
       "      <th>Share_21_22</th>\n",
       "      <th>GDP_billion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>13.17%</td>\n",
       "      <td>414.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>2,700,109</td>\n",
       "      <td>2,364,514</td>\n",
       "      <td>8.78%</td>\n",
       "      <td>276.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>2,500,733</td>\n",
       "      <td>2,269,995</td>\n",
       "      <td>8.38%</td>\n",
       "      <td>264.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>2,547,861</td>\n",
       "      <td>2,258,040</td>\n",
       "      <td>8.37%</td>\n",
       "      <td>263.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>2,230,609</td>\n",
       "      <td>8.17%</td>\n",
       "      <td>257.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,700,939</td>\n",
       "      <td>1,531,758</td>\n",
       "      <td>5.63%</td>\n",
       "      <td>177.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,524,030</td>\n",
       "      <td>1,365,849</td>\n",
       "      <td>5.06%</td>\n",
       "      <td>159.334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>1,439,674</td>\n",
       "      <td>1,303,524</td>\n",
       "      <td>4.87%</td>\n",
       "      <td>153.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>1,463,960</td>\n",
       "      <td>1,308,034</td>\n",
       "      <td>4.76%</td>\n",
       "      <td>150.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>1,363,327</td>\n",
       "      <td>1,246,471</td>\n",
       "      <td>4.63%</td>\n",
       "      <td>145.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>1,046,188</td>\n",
       "      <td>3.96%</td>\n",
       "      <td>124.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>1,107,746</td>\n",
       "      <td>1,014,688</td>\n",
       "      <td>3.73%</td>\n",
       "      <td>117.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>1,095,535</td>\n",
       "      <td>984,055</td>\n",
       "      <td>3.68%</td>\n",
       "      <td>116.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>832,790</td>\n",
       "      <td>753,177</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>88.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>-</td>\n",
       "      <td>751,396</td>\n",
       "      <td>2.76%</td>\n",
       "      <td>86.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>736,423</td>\n",
       "      <td>676,164</td>\n",
       "      <td>2.62%</td>\n",
       "      <td>82.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>565,401</td>\n",
       "      <td>493,167</td>\n",
       "      <td>1.74%</td>\n",
       "      <td>54.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>505,887</td>\n",
       "      <td>464,399</td>\n",
       "      <td>1.74%</td>\n",
       "      <td>54.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>-</td>\n",
       "      <td>393,722</td>\n",
       "      <td>1.52%</td>\n",
       "      <td>47.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>346,206</td>\n",
       "      <td>303,781</td>\n",
       "      <td>1.13%</td>\n",
       "      <td>35.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>246,465</td>\n",
       "      <td>224,226</td>\n",
       "      <td>0.82%</td>\n",
       "      <td>25.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>207,430</td>\n",
       "      <td>191,728</td>\n",
       "      <td>0.73%</td>\n",
       "      <td>22.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>-</td>\n",
       "      <td>93,672</td>\n",
       "      <td>0.36%</td>\n",
       "      <td>11.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>-</td>\n",
       "      <td>72,636</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>8.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>54,285</td>\n",
       "      <td>0.20%</td>\n",
       "      <td>6.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>-</td>\n",
       "      <td>49,643</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>5.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>47,381</td>\n",
       "      <td>42,697</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>5.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>-</td>\n",
       "      <td>42,756</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>5.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>4.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>39,630</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>35,643</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>1.385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP_23_24 GSDP_22_23 Share_21_22  \\\n",
       "0     1                Maharashtra          -          -      13.17%   \n",
       "1     2                 Tamil Nadu  2,700,109  2,364,514       8.78%   \n",
       "2     3                  Karnataka  2,500,733  2,269,995       8.38%   \n",
       "3     4              Uttar Pradesh  2,547,861  2,258,040       8.37%   \n",
       "4     5                    Gujarat          -  2,230,609       8.17%   \n",
       "5     6                West Bengal  1,700,939  1,531,758       5.63%   \n",
       "6     7                  Rajasthan  1,524,030  1,365,849       5.06%   \n",
       "7     8             Andhra Pradesh  1,439,674  1,303,524       4.87%   \n",
       "8     9                  Telangana  1,463,960  1,308,034       4.76%   \n",
       "9    10             Madhya Pradesh  1,363,327  1,246,471       4.63%   \n",
       "10   11                     Kerala          -  1,046,188       3.96%   \n",
       "11   12                      Delhi  1,107,746  1,014,688       3.73%   \n",
       "12   13                    Haryana  1,095,535    984,055       3.68%   \n",
       "13   14                     Odisha    832,790    753,177       2.81%   \n",
       "14   15                      Bihar          -    751,396       2.76%   \n",
       "15   16                     Punjab    736,423    676,164       2.62%   \n",
       "16   17                      Assam    565,401    493,167       1.74%   \n",
       "17   18               Chhattisgarh    505,887    464,399       1.74%   \n",
       "18   19                  Jharkhand          -    393,722       1.52%   \n",
       "19   20                Uttarakhand    346,206    303,781       1.13%   \n",
       "20   21            Jammu & Kashmir    246,465    224,226       0.82%   \n",
       "21   22           Himachal Pradesh    207,430    191,728       0.73%   \n",
       "22   23                        Goa          -     93,672       0.36%   \n",
       "23   24                    Tripura          -     72,636       0.27%   \n",
       "24   25                 Chandigarh          -     54,285       0.20%   \n",
       "25   26                 Puducherry          -     49,643       0.19%   \n",
       "26   27                  Meghalaya     47,381     42,697       0.16%   \n",
       "27   28                     Sikkim          -     42,756       0.16%   \n",
       "28   29                    Manipur          -          -       0.16%   \n",
       "29   30          Arunachal Pradesh          -     39,630       0.15%   \n",
       "30   31                   Nagaland          -     35,643       0.13%   \n",
       "31   32                    Mizoram          -          -       0.12%   \n",
       "32   33  Andaman & Nicobar Islands          -          -       0.04%   \n",
       "\n",
       "   GDP_billion  \n",
       "0      414.928  \n",
       "1      276.522  \n",
       "2      264.080  \n",
       "3      263.747  \n",
       "4      257.484  \n",
       "5      177.456  \n",
       "6      159.334  \n",
       "7      153.324  \n",
       "8      150.084  \n",
       "9      145.913  \n",
       "10     124.764  \n",
       "11     117.660  \n",
       "12     116.001  \n",
       "13      88.497  \n",
       "14      86.817  \n",
       "15      82.397  \n",
       "16      54.930  \n",
       "17      54.806  \n",
       "18      47.909  \n",
       "19      35.664  \n",
       "20      25.813  \n",
       "21      22.984  \n",
       "22      11.250  \n",
       "23       8.351  \n",
       "24       6.154  \n",
       "25       5.849  \n",
       "26       5.178  \n",
       "27       5.014  \n",
       "28       4.885  \n",
       "29       4.643  \n",
       "30       4.144  \n",
       "31       3.715  \n",
       "32       1.385  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7256b4",
   "metadata": {},
   "source": [
    "4.Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14a4c55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import ElementNotInteractableException,NoSuchElementException\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c1e9d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElementNotInteractableException Message: element not interactable\n",
      "  (Session info: chrome=123.0.6312.88)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF709A970C2+63090]\n",
      "\t(No symbol) [0x00007FF709A02D12]\n",
      "\t(No symbol) [0x00007FF70989EB1D]\n",
      "\t(No symbol) [0x00007FF7098E5D56]\n",
      "\t(No symbol) [0x00007FF7098DA708]\n",
      "\t(No symbol) [0x00007FF709906FDA]\n",
      "\t(No symbol) [0x00007FF7098DA00A]\n",
      "\t(No symbol) [0x00007FF7099071F0]\n",
      "\t(No symbol) [0x00007FF709923412]\n",
      "\t(No symbol) [0x00007FF709906D83]\n",
      "\t(No symbol) [0x00007FF7098D83A8]\n",
      "\t(No symbol) [0x00007FF7098D9441]\n",
      "\tGetHandleVerifier [0x00007FF709E9262D+4238301]\n",
      "\tGetHandleVerifier [0x00007FF709ECF78D+4488509]\n",
      "\tGetHandleVerifier [0x00007FF709EC7A6F+4456479]\n",
      "\tGetHandleVerifier [0x00007FF709B70606+953270]\n",
      "\t(No symbol) [0x00007FF709A0E5DF]\n",
      "\t(No symbol) [0x00007FF709A092B4]\n",
      "\t(No symbol) [0x00007FF709A093EB]\n",
      "\t(No symbol) [0x00007FF7099F9C24]\n",
      "\tBaseThreadInitThunk [0x00007FFBDA887344+20]\n",
      "\tRtlUserThreadStart [0x00007FFBDB9426B1+33]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome()\n",
    "url = \"https://github.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "\n",
    "try:\n",
    "    menu_element=driver.find_element(By.XPATH,'//span[@class=\"Button-content\"]/span')\n",
    "    menu_element.click()\n",
    "except ElementNotInteractableException as e:\n",
    "    print(\"ElementNotInteractableException\",e)\n",
    "    \n",
    "try:\n",
    "    source_element=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')\n",
    "    source_element.click()\n",
    "except ElementNotInteractableException as e:\n",
    "    print(\"ElementNotInteractableException\",e)\n",
    "    \n",
    "    \n",
    "try:\n",
    "    trending_repos=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')\n",
    "    trending_repos.click()\n",
    "except ElementNotInteractableException as e:\n",
    "    print(\"ElementNotInteractableException\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba0d4cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "title=[]\n",
    "description=[]\n",
    "count=[]\n",
    "language=[]\n",
    "\n",
    "\n",
    "title_element=driver.find_elements(By.XPATH,'//h2[@class=\"h3 lh-condensed\"]')\n",
    "for titles in title_element:\n",
    "    title.append(titles.text)\n",
    "    \n",
    "\n",
    "try:\n",
    "    description_element=driver.find_elements(By.XPATH,'//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "    for descriptions in description_element:\n",
    "        description.append(descriptions.text)\n",
    "except NoSuchElementException:\n",
    "    description.append(\"-\")\n",
    "        \n",
    "        \n",
    "count_element=driver.find_elements(By.XPATH,'//a[@class=\"Link Link--muted d-inline-block mr-3\"][2]')\n",
    "for counts in count_element:\n",
    "    count.append(counts.text)\n",
    "\n",
    "    \n",
    "\n",
    "try:\n",
    "    language_element=driver.find_elements(By.XPATH,'//span[@class=\"d-inline-block ml-0 mr-3\"]')\n",
    "    for languages in language_element:\n",
    "        language.append(languages.text)\n",
    "except NoSuchElementException:\n",
    "    language.append(\"-\")\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "driver.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15495ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 24 25 24\n"
     ]
    }
   ],
   "source": [
    "print(len(title),len(description),len(count),len(language))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802e8487",
   "metadata": {},
   "source": [
    "5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the\n",
    "following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    " Note: - From the home page you have to click on the charts option then hot 100-page link through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0960e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5570ff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "Url = \"https:/www.billboard.com/\"\n",
    "driver.get(Url)\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "try:\n",
    "    song_menu=WebDriverWait(driver,5).until(EC.presence_of_element_located((By.XPATH,'//div[@class=\" lrv-a-space-children-horizontal lrv-a-space-children--150 lrv-u-margin-t-1 lrv-u-flex lrv-u-justify-content-space-between lrv-u-overflow-auto a-homepage-chart-links\"]/a')))\n",
    "    song_menu.click()\n",
    "except ElementNotInteractableException as e:\n",
    "    print(\"ElementNotInteractableException\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a96747f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_name=[]\n",
    "artist_name=[]\n",
    "last_rank=[]\n",
    "peak_rank=[]\n",
    "week_chart=[]\n",
    "\n",
    "\n",
    "song_element=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li/h3')\n",
    "for song in song_element:\n",
    "    song_name.append(song.text)\n",
    "    \n",
    "\n",
    "\n",
    "artist_element=driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]/li[1]')\n",
    "for artist in artist_element:\n",
    "     artist_name.append(artist.text)\n",
    "    \n",
    "time.sleep(2)   \n",
    "        \n",
    "try:\n",
    "    rank_element=driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-row u-background-color-grey-lightest@mobile-max\"]/li[3]')\n",
    "    for rank in rank_element:\n",
    "        last_rank.append(rank.text)\n",
    "except ElementNotInteractableException as e:\n",
    "    print(\"ElementNotInteractableException\",e)\n",
    "\n",
    "    \n",
    "try:\n",
    "    peak_element=driver.find_elements(By.XPATH,'//li[@class=\"o-chart-results-list__item // a-chart-bg-color a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-background-color-grey-lightest lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light lrv-u-flex-grow-1\"]/span')\n",
    "    for peak in peak_element:\n",
    "        peak_rank.append(peak.text)\n",
    "except ElementNotInteractableException as e:\n",
    "    print(\"ElementNotInteractableException\",e)    \n",
    "    \n",
    "try:\n",
    "    chart_element=driver.find_elements(By.XPATH,'//li[@class=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max lrv-u-flex-grow-1\"][2]')\n",
    "    for chart in chart_element:\n",
    "        week_chart.append(chart.text)\n",
    "except ElementNotInteractableException as e:\n",
    "    print(\"ElementNotInteractableException\",e)    \n",
    "\n",
    "    \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea2eb99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 200 200 200 200\n"
     ]
    }
   ],
   "source": [
    "print(len(song_name),len(artist_name),len(last_rank),len(peak_rank),len(week_chart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f613eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_song=pd.DataFrame({\"Song_name\":song_name,\"Artist_name\":artist_name,\"Last_rank\":last_rank,\"Peak_rank\":peak_rank,\"Week_chart\":week_chart})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9c60f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_song = df_song.iloc[0:100, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "93ddf53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_song)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5df8f6d",
   "metadata": {},
   "source": [
    "6. Scrape the details of Highest selling novels.\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n",
    " Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "96062285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0cf11864",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\"\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(url)\n",
    "time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "52bd3a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_name=[]\n",
    "author_name=[]\n",
    "volume_sold=[]\n",
    "publisher=[]\n",
    "genre_url=[]\n",
    "\n",
    "\n",
    "book_element=driver.find_elements(By.XPATH,'//div[@class=\"embed block\"]/table/tbody/tr/td[2]')\n",
    "for book in book_element:\n",
    "    book_name.append(book.text)\n",
    "    \n",
    "\n",
    "\n",
    "author_element=driver.find_elements(By.XPATH,'//div[@class=\"embed block\"]/table/tbody/tr/td[3]')\n",
    "for author in author_element:\n",
    "     author_name.append(author.text)\n",
    "    \n",
    "time.sleep(2)   \n",
    "        \n",
    "volume_element=driver.find_elements(By.XPATH,'//div[@class=\"embed block\"]/table/tbody/tr/td[4]')\n",
    "for volume in volume_element:\n",
    "     volume_sold.append(volume.text)\n",
    "\n",
    "    \n",
    "publisher_element=driver.find_elements(By.XPATH,'//div[@class=\"embed block\"]/table/tbody/tr/td[5]')\n",
    "for publish in publisher_element:\n",
    "     publisher.append(publish.text)\n",
    "    \n",
    "try:\n",
    "    url_element=driver.find_elements(By.XPATH,'//div[@class=\"embed block\"]/table/tbody/tr/td[6]')\n",
    "    for url in url_element:\n",
    "        genre_url.append(url.text)\n",
    "except WebDriverException as e:\n",
    "    print(\"WebDriverException\",e)\n",
    "    \n",
    "\n",
    "driver.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "28bfd09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(book_name),len(author_name),len(volume_sold),len(publisher),len(genre_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3300a662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_name</th>\n",
       "      <th>Author_name</th>\n",
       "      <th>Volume_sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book_name       Author_name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume_sold        Publisher                    Genre_url  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_novel=pd.DataFrame({\"Book_name\":book_name,\"Author_name\":author_name,\"Volume_sold\":volume_sold,\"Publisher\":publisher,\"Genre_url\":genre_url})\n",
    "df_novel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e07387",
   "metadata": {},
   "source": [
    "7. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/ You have\n",
    "to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bf87ceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import WebDriverException, NoSuchElementException\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3dc8ceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.imdb.com/chart/toptv/?ref_=nv_tvv_250\"\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e9f5ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "31a52404",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "year_span=[]\n",
    "genre=[]\n",
    "run_time=[]\n",
    "ratings=[]\n",
    "votes=[]\n",
    "\n",
    "\n",
    "name_element=driver.find_elements(By.XPATH,'//div[@class=\"sc-b0691f29-0 jbYPfh cli-children\"]/div[1]')\n",
    "for title in name_element:\n",
    "    name.append(title.text)\n",
    "    \n",
    "year_element=driver.find_elements(By.XPATH,'//div[@class=\"sc-b0691f29-7 hrgukm cli-title-metadata\"]/span[1]')\n",
    "for year in year_element:\n",
    "    year_span.append(year.text)\n",
    "    \n",
    "\n",
    "genre_element=driver.find_elements(By.XPATH,'//div[@class=\"sc-b0691f29-7 hrgukm cli-title-metadata\"]/span[3]')\n",
    "for gen in genre_element:\n",
    "    genre.append(gen.text if gen.text else \"-\")\n",
    "    \n",
    "while len(genre)<250:\n",
    "    genre.append(\"-\")\n",
    "\n",
    "run_time_element=driver.find_elements(By.XPATH,'//div[@class=\"sc-b0691f29-7 hrgukm cli-title-metadata\"]/span[2]')\n",
    "for run in run_time_element:\n",
    "    run_time.append(run.text)\n",
    "    \n",
    "ratings_element=driver.find_elements(By.XPATH,'//span[@class=\"sc-b0691f29-1 grHDBY\"]/div/span')\n",
    "for rating in ratings_element:\n",
    "    ratings.append(rating.text)\n",
    "    \n",
    "votes_element=driver.find_elements(By.XPATH,'//span[@class=\"ipc-rating-star--voteCount\"]')\n",
    "for vote in votes_element:\n",
    "    votes.append(vote.text)\n",
    "    \n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a6ee0215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 250 250 250 250 250\n"
     ]
    }
   ],
   "source": [
    "print(len(name),len(year_span),len(genre),len(run_time),len(ratings),len(votes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2ec29e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "502f85b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['9.5', '2.1'], ['9.5'], ['9.4'], ['9.4'], ['9.3'], ['9.3'], ['9.3'], ['9.3'], ['9.2'], ['9.3'], ['9.3'], ['9.3'], ['9.2', '2.3'], ['9.2'], ['9.4'], ['9.1'], ['9.1'], ['9.1'], ['9.1'], ['9.1'], ['9.1'], ['9.1'], ['9.0'], ['9.1'], ['9.1'], ['9.3'], ['9.0'], ['9.0'], ['9.0'], ['9.0'], ['9.0'], ['9.0'], ['9.0'], ['9.0'], ['9.0'], ['9.0'], ['8.9'], ['9.0'], ['8.9'], ['9.0'], ['8.9'], ['8.9'], ['8.9'], ['9.0'], ['8.9'], ['8.9'], ['8.9'], ['9.0'], ['9.0'], ['8.8'], ['8.9'], ['9.0'], ['8.9'], ['8.9', '1.1'], ['8.8'], ['9.1'], ['8.8'], ['8.8'], ['8.9'], ['8.8'], ['8.8'], ['9.0'], ['8.8'], ['8.8'], ['9.1'], ['8.8'], ['8.8'], ['8.8'], ['8.8'], ['8.8'], ['8.8'], ['8.8'], ['8.8'], ['9.1'], ['8.8'], ['8.7'], ['8.7'], ['8.8'], ['8.8'], ['9.0'], ['8.8'], ['9.0'], ['9.1'], ['8.8'], ['8.7'], ['8.7'], ['8.7'], ['8.9'], ['8.7'], ['8.8'], ['8.7'], ['9.0'], ['8.7'], ['8.7'], ['8.7'], ['8.7'], ['8.7'], ['8.7'], ['8.7'], ['8.7'], ['8.7'], ['8.7'], ['8.7'], ['8.7'], ['8.7'], ['8.7'], ['8.7'], ['8.7'], ['8.7', '1.3'], ['8.7'], ['8.9'], ['8.7'], ['8.7'], ['8.7'], ['9.2'], ['8.7'], ['8.7'], ['8.7'], ['8.7'], ['8.7'], ['8.9'], ['8.9'], ['8.7'], ['8.7'], ['8.7'], ['8.7'], ['8.7'], ['8.6'], ['8.7'], ['9.0'], ['8.6'], ['8.6'], ['8.6'], ['8.6'], ['8.6'], ['8.6'], ['8.7'], ['9.2'], ['8.7'], ['8.7'], ['8.6'], ['8.6'], ['8.6'], ['8.6'], ['8.6'], ['8.7'], ['8.6'], ['9.0'], ['8.7'], ['8.7'], ['8.6'], ['8.6'], ['8.6'], ['8.6'], ['8.6'], ['8.7'], ['8.6'], ['8.6'], ['8.6'], ['8.6'], ['8.6'], ['8.6'], ['8.7'], ['8.6'], ['8.7'], ['8.7'], ['8.7'], ['8.6'], ['8.6'], ['8.7'], ['8.6'], ['8.6'], ['8.6'], ['8.6'], ['8.7'], ['8.7'], ['8.6'], ['8.7'], ['8.6'], ['8.6'], ['8.6'], ['8.6'], ['8.6'], ['8.7'], ['8.5'], ['8.5'], ['8.5'], ['8.6'], ['8.5'], ['8.6'], ['8.9'], ['8.6'], ['8.6'], ['8.9'], ['8.6'], ['8.6'], ['8.6'], ['8.5'], ['8.5'], ['8.5'], ['8.7'], ['8.6'], ['8.6'], ['8.6'], ['8.5'], ['8.6'], ['8.5'], ['8.5'], ['8.5'], ['8.5'], ['8.6'], ['8.5'], ['8.5'], ['8.6'], ['8.6'], ['8.5'], ['8.5'], ['8.5'], ['8.5'], ['8.6'], ['8.6'], ['8.5'], ['8.5'], ['8.6'], ['8.5'], ['8.6'], ['8.5'], ['8.5'], ['8.6'], ['8.5'], ['8.6'], ['8.5'], ['8.5'], ['8.6'], ['8.6'], ['8.5'], ['8.5'], ['8.6'], ['8.5'], ['8.6'], ['8.7'], ['8.8'], ['8.6'], ['8.5'], ['8.6'], ['8.5'], ['8.7'], ['8.5'], ['8.6'], ['8.5']]\n"
     ]
    }
   ],
   "source": [
    "def ratings_extract(likes):\n",
    "    view=[]\n",
    "    for item in likes:\n",
    "        pattern=re.findall(r\"\\d+\\.\\d+\", item)\n",
    "        view.append(pattern)\n",
    "    return view\n",
    "   \n",
    "\n",
    "\n",
    "star=ratings_extract(ratings)\n",
    "print(star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b23cc515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year_span</th>\n",
       "      <th>genre</th>\n",
       "      <th>run_time</th>\n",
       "      <th>ratings</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Breaking Bad</td>\n",
       "      <td>2008–2013</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>62 eps</td>\n",
       "      <td>[9.5, 2.1]</td>\n",
       "      <td>(2.1M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Planet Earth II</td>\n",
       "      <td>2016</td>\n",
       "      <td>TV-G</td>\n",
       "      <td>6 eps</td>\n",
       "      <td>[9.5]</td>\n",
       "      <td>(157K)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. Planet Earth</td>\n",
       "      <td>2006</td>\n",
       "      <td>TV-PG</td>\n",
       "      <td>11 eps</td>\n",
       "      <td>[9.4]</td>\n",
       "      <td>(219K)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. Band of Brothers</td>\n",
       "      <td>2001</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>10 eps</td>\n",
       "      <td>[9.4]</td>\n",
       "      <td>(524K)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. Chernobyl</td>\n",
       "      <td>2019</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>5 eps</td>\n",
       "      <td>[9.3]</td>\n",
       "      <td>(860K)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>246. Your Lie in April</td>\n",
       "      <td>2014–2015</td>\n",
       "      <td>-</td>\n",
       "      <td>24 eps</td>\n",
       "      <td>[8.5]</td>\n",
       "      <td>(37K)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>247. Gintama</td>\n",
       "      <td>2005–2021</td>\n",
       "      <td>-</td>\n",
       "      <td>375 eps</td>\n",
       "      <td>[8.7]</td>\n",
       "      <td>(15K)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>248. Chef's Table</td>\n",
       "      <td>2015–2019</td>\n",
       "      <td>-</td>\n",
       "      <td>30 eps</td>\n",
       "      <td>[8.5]</td>\n",
       "      <td>(17K)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>249. Foyle's War</td>\n",
       "      <td>2002–2015</td>\n",
       "      <td>-</td>\n",
       "      <td>28 eps</td>\n",
       "      <td>[8.6]</td>\n",
       "      <td>(18K)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>250. The Boondocks</td>\n",
       "      <td>2005–2014</td>\n",
       "      <td>-</td>\n",
       "      <td>56 eps</td>\n",
       "      <td>[8.5]</td>\n",
       "      <td>(36K)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  year_span  genre run_time     ratings    votes\n",
       "0           1. Breaking Bad  2008–2013  TV-MA   62 eps  [9.5, 2.1]   (2.1M)\n",
       "1        2. Planet Earth II       2016   TV-G    6 eps       [9.5]   (157K)\n",
       "2           3. Planet Earth       2006  TV-PG   11 eps       [9.4]   (219K)\n",
       "3       4. Band of Brothers       2001  TV-MA   10 eps       [9.4]   (524K)\n",
       "4              5. Chernobyl       2019  TV-MA    5 eps       [9.3]   (860K)\n",
       "..                      ...        ...    ...      ...         ...      ...\n",
       "245  246. Your Lie in April  2014–2015      -   24 eps       [8.5]    (37K)\n",
       "246            247. Gintama  2005–2021      -  375 eps       [8.7]    (15K)\n",
       "247       248. Chef's Table  2015–2019      -   30 eps       [8.5]    (17K)\n",
       "248        249. Foyle's War  2002–2015      -   28 eps       [8.6]    (18K)\n",
       "249      250. The Boondocks  2005–2014      -   56 eps       [8.5]    (36K)\n",
       "\n",
       "[250 rows x 6 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_series=pd.DataFrame({\"name\":name,\"year_span\":year_span,\"genre\":genre,\"run_time\":run_time,\"ratings\":star,\"votes\":votes})\n",
    "\n",
    "df_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbd2cdb",
   "metadata": {},
   "source": [
    "8. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/ You\n",
    "have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute G) Year\n",
    " Note: - from the home page you have to go to the Show All Dataset page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74e6e911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import JavascriptException, NoSuchElementException,ElementClickInterceptedException\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03fd1b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ \"\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "more_dataset=driver.find_element(By.XPATH,'//div[@class=\"hero\"]/div/div/div/a[1]')\n",
    "more_dataset.click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "expand_dt=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[1]/div/label[2]/div[2]/span[2]')\n",
    "expand_dt.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27c2ed3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name=[]\n",
    "data_type=[]\n",
    "task=[]\n",
    "attribute_type=[]\n",
    "num_instance=[]\n",
    "num_attribute=[]\n",
    "year_note=[]\n",
    "\n",
    "\n",
    "\n",
    "name_element=driver.find_elements(By.XPATH,'//div[@class=\"relative col-span-8 sm:col-span-7\"]/h2/a')\n",
    "for title in name_element:\n",
    "    dataset_name.append(title.text)\n",
    "\n",
    "data_element=driver.find_elements(By.XPATH,'//div[@class=\"relative col-span-8 sm:col-span-7\"]/p')\n",
    "for data in data_element:\n",
    "    data_type.append(data.text)\n",
    "\n",
    "\n",
    "task_element=driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[1]/span')\n",
    "for tasks in task_element:\n",
    "    task.append(tasks.text)\n",
    "\n",
    "\n",
    "attribute_element=driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[2]/span')\n",
    "for attribute in attribute_element:\n",
    "    attribute_type.append(attribute.text)\n",
    "    \n",
    "instance_element=driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[3]/span')\n",
    "for instance in instance_element:\n",
    "    num_instance.append(instance.text)\n",
    "\n",
    "num_attribute_element=driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[4]/span')\n",
    "for num in num_attribute_element:\n",
    "    num_attribute.append(num.text)\n",
    "    \n",
    "year_element=driver.find_elements(By.XPATH,'//table[@class=\"col-span-full my-2 table sm:col-start-2\"]/tbody/tr/td[3]')\n",
    "for year in year_element:\n",
    "    year_note.append(year.text)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84f9a88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_name),len(data_type),len(task),len(attribute_type),len(num_instance),len(num_attribute),len(year_note))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ffcc2148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>data_type</th>\n",
       "      <th>task</th>\n",
       "      <th>attribute_type</th>\n",
       "      <th>num_instance</th>\n",
       "      <th>num_attribute</th>\n",
       "      <th>year_note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>A small classic dataset from Fisher, 1936. One...</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>150 Instances</td>\n",
       "      <td>4 Features</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dry Bean</td>\n",
       "      <td>Images of 13,611 grains of 7 different registe...</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>13.61K Instances</td>\n",
       "      <td>16 Features</td>\n",
       "      <td>9/14/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>4 databases: Cleveland, Hungary, Switzerland, ...</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>303 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>A total of 3810 rice grain's images were taken...</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>3.81K Instances</td>\n",
       "      <td>7 Features</td>\n",
       "      <td>10/6/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Predict whether income exceeds $50K/yr based o...</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>14 Features</td>\n",
       "      <td>5/1/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Raisin</td>\n",
       "      <td>Images of the Kecimen and Besni raisin varieti...</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>900 Instances</td>\n",
       "      <td>8 Features</td>\n",
       "      <td>8/14/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Diagnostic Wisconsin Breast Cancer Database.</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>569 Instances</td>\n",
       "      <td>30 Features</td>\n",
       "      <td>11/1/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Using chemical analysis to determine the origi...</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>178 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>7/1/1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wine Quality</td>\n",
       "      <td>Two datasets are included, related to red and ...</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>4.9K Instances</td>\n",
       "      <td>12 Features</td>\n",
       "      <td>10/7/2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>This diabetes dataset is from AIM '94</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>1 Instances</td>\n",
       "      <td>20 Features</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           dataset_name  \\\n",
       "0                                  Iris   \n",
       "1                              Dry Bean   \n",
       "2                         Heart Disease   \n",
       "3            Rice (Cammeo and Osmancik)   \n",
       "4                                 Adult   \n",
       "5                                Raisin   \n",
       "6  Breast Cancer Wisconsin (Diagnostic)   \n",
       "7                                  Wine   \n",
       "8                          Wine Quality   \n",
       "9                              Diabetes   \n",
       "\n",
       "                                           data_type  \\\n",
       "0  A small classic dataset from Fisher, 1936. One...   \n",
       "1  Images of 13,611 grains of 7 different registe...   \n",
       "2  4 databases: Cleveland, Hungary, Switzerland, ...   \n",
       "3  A total of 3810 rice grain's images were taken...   \n",
       "4  Predict whether income exceeds $50K/yr based o...   \n",
       "5  Images of the Kecimen and Besni raisin varieti...   \n",
       "6       Diagnostic Wisconsin Breast Cancer Database.   \n",
       "7  Using chemical analysis to determine the origi...   \n",
       "8  Two datasets are included, related to red and ...   \n",
       "9              This diabetes dataset is from AIM '94   \n",
       "\n",
       "                         task             attribute_type      num_instance  \\\n",
       "0              Classification                    Tabular     150 Instances   \n",
       "1              Classification               Multivariate  13.61K Instances   \n",
       "2              Classification               Multivariate     303 Instances   \n",
       "3              Classification               Multivariate   3.81K Instances   \n",
       "4              Classification               Multivariate  48.84K Instances   \n",
       "5              Classification               Multivariate     900 Instances   \n",
       "6              Classification               Multivariate     569 Instances   \n",
       "7              Classification                    Tabular     178 Instances   \n",
       "8  Classification, Regression               Multivariate    4.9K Instances   \n",
       "9              Classification  Multivariate, Time-Series       1 Instances   \n",
       "\n",
       "  num_attribute  year_note  \n",
       "0    4 Features   7/1/1988  \n",
       "1   16 Features  9/14/2020  \n",
       "2   13 Features   7/1/1988  \n",
       "3    7 Features  10/6/2019  \n",
       "4   14 Features   5/1/1996  \n",
       "5    8 Features  8/14/2023  \n",
       "6   30 Features  11/1/1995  \n",
       "7   13 Features   7/1/1991  \n",
       "8   12 Features  10/7/2009  \n",
       "9   20 Features        N/A  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data=pd.DataFrame({\"dataset_name\":dataset_name,\"data_type\":data_type,\"task\":task,\"attribute_type\":attribute_type,\"num_instance\":num_instance,\"num_attribute\":num_attribute,\"year_note\":year_note})\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89155ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
